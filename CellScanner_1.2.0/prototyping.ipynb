{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import callbacks\n",
    "\n",
    "from utilities.classification_utils import ClassificationModel\n",
    "from utilities.data_preparation import FilePreparation, DataPreparation\n",
    "from utilities.settings import Settings\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Bacteroides_uniformis-050520-mGAM-2.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/.DS_Store',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Blautia_hydrogenotrophica-211119-GAM-2.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Blautia_hydrogenotrophica-211119-GAM-1.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Bacteroides_thetaiotaomicron-050520-mGAM-1.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Bacteroides_uniformis-130520-mGAM-1.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Blautia_hydrogenotrophica-130520-mGAM-1.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Bacteroides_thetaiotaomicron-050520-mGAM-2.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Escherichia_coli-050520-mGAM-1.fcs',\n '/Users/v_vlsv/PyCharmProjects/CellScanner/CellScanner_1.2.0/ref_sel/Escherichia_coli-050520-mGAM-2.fcs']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [os.path.abspath(os.path.join(\"./ref_sel\", p)) for p in os.listdir(\"./ref_sel\")]\n",
    "files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 00:41:31.007260: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-02 00:41:31.007390: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "[[3.291591  3.1373541 5.6044507 ... 4.644793  4.123231  3.4116197]\n",
      " [3.3558345 3.109241  4.341197  ... 3.5118833 3.155943  2.6541765]\n",
      " [3.6379898 3.0330215 5.145231  ... 4.1882815 3.5434473 3.191451 ]\n",
      " ...\n",
      " [4.211761  2.7678976 4.2997904 ... 3.3539162 2.7923918 2.269513 ]\n",
      " [3.8541846 3.1917305 4.517618  ... 3.636488  3.2882493 3.0220158]\n",
      " [4.1459417 3.1182647 4.4678154 ... 3.5602653 2.9164538 2.690196 ]] tf.Tensor([1. 1. 1. ... 3. 3. 3.], shape=(37377,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "files.pop(1)\n",
    "file_preparation = FilePreparation(files=files, settings=Settings())\n",
    "dataframe = file_preparation.get_aggregated()\n",
    "labels = file_preparation.get_labels()\n",
    "labels_shape = file_preparation.get_labels_shape()\n",
    "data_preparation = DataPreparation(dataframe=dataframe, labels=labels, batch_size=512)\n",
    "training_set, test_set = data_preparation.create_datasets()\n",
    "feature_shape = None\n",
    "for elem in training_set.take(1):\n",
    " \tfeature_shape = elem[0][\"input_1\"][0].shape\n",
    "\n",
    "# After modification ClassificationModel needs extra arguments at class instantiating\n",
    "model = ClassificationModel(num_classes=labels_shape, num_features=feature_shape, fc_type=\"Accuri\", lr=1e-3).get_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def plot():\n",
    "\tfrom matplotlib import pyplot as plt\n",
    "\n",
    "\tplt.figure(figsize=(15,8))\n",
    "\tplt.subplot(1, 2, 1)\n",
    "\tplt.plot(history.history[\"accuracy\"])\n",
    "\tplt.plot(history.history[\"val_accuracy\"])\n",
    "\tplt.title(\"Model Accuracy\")\n",
    "\tplt.ylabel(\"Accuracy\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\n",
    "\tplt.subplot(1, 2, 2)\n",
    "\tplt.plot(history.history[\"loss\"])\n",
    "\tplt.plot(history.history[\"val_loss\"])\n",
    "\tplt.title(\"Loss Function\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 23:03:49.085678: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-16 23:03:49.085758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - ETA: 0s - loss: 1.8830 - accuracy: 0.4001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 23:03:58.822952: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 11s 23ms/step - loss: 1.8830 - accuracy: 0.4001 - val_loss: 1.8055 - val_accuracy: 0.3437 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009999980475013564.\n",
      "Epoch 2/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.5493 - accuracy: 0.4658 - val_loss: 1.5034 - val_accuracy: 0.4665 - lr: 1.0000e-03\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009999940684607064.\n",
      "Epoch 3/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.3073 - accuracy: 0.5420 - val_loss: 1.4205 - val_accuracy: 0.5082 - lr: 9.9999e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000999988110387376.\n",
      "Epoch 4/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.1645 - accuracy: 0.5839 - val_loss: 1.2479 - val_accuracy: 0.5448 - lr: 9.9999e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009999800568788481.\n",
      "Epoch 5/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 1.1518 - accuracy: 0.5926 - val_loss: 1.1168 - val_accuracy: 0.5910 - lr: 9.9998e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0009999700243618534.\n",
      "Epoch 6/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 1.0978 - accuracy: 0.6058 - val_loss: 1.0283 - val_accuracy: 0.6283 - lr: 9.9997e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0009999580128482659.\n",
      "Epoch 7/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 1.0690 - accuracy: 0.6105 - val_loss: 1.0109 - val_accuracy: 0.6325 - lr: 9.9996e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000999944022349959.\n",
      "Epoch 8/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 1.0375 - accuracy: 0.6215 - val_loss: 1.0322 - val_accuracy: 0.6182 - lr: 9.9994e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0009999280528788066.\n",
      "Epoch 9/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.0365 - accuracy: 0.6236 - val_loss: 0.9570 - val_accuracy: 0.6466 - lr: 9.9993e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009999101044466821.\n",
      "Epoch 10/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 1.0459 - accuracy: 0.6191 - val_loss: 0.9884 - val_accuracy: 0.6333 - lr: 9.9991e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009998900606524661.\n",
      "Epoch 11/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.0566 - accuracy: 0.6191 - val_loss: 0.9976 - val_accuracy: 0.6402 - lr: 9.9989e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009998680379214907.\n",
      "Epoch 12/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.0262 - accuracy: 0.6294 - val_loss: 0.9745 - val_accuracy: 0.6462 - lr: 9.9987e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009998440362656291.\n",
      "Epoch 13/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9981 - accuracy: 0.6360 - val_loss: 0.9571 - val_accuracy: 0.6445 - lr: 9.9984e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.000999818055696755.\n",
      "Epoch 14/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 1.0204 - accuracy: 0.6304 - val_loss: 1.0041 - val_accuracy: 0.6297 - lr: 9.9982e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0009997900962267416.\n",
      "Epoch 15/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9915 - accuracy: 0.6373 - val_loss: 1.0792 - val_accuracy: 0.5991 - lr: 9.9979e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0009997601578674614.\n",
      "Epoch 16/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9926 - accuracy: 0.6363 - val_loss: 0.9341 - val_accuracy: 0.6569 - lr: 9.9976e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.000999728124219191.\n",
      "Epoch 17/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9656 - accuracy: 0.6450 - val_loss: 0.9357 - val_accuracy: 0.6536 - lr: 9.9973e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0009996941117058655.\n",
      "Epoch 18/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9611 - accuracy: 0.6462 - val_loss: 1.0849 - val_accuracy: 0.6003 - lr: 9.9969e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000999658120339358.\n",
      "Epoch 19/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9680 - accuracy: 0.6433 - val_loss: 0.9498 - val_accuracy: 0.6480 - lr: 9.9966e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0009996201501315406.\n",
      "Epoch 20/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9637 - accuracy: 0.6462 - val_loss: 1.1911 - val_accuracy: 0.5668 - lr: 9.9962e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000999580201094286.\n",
      "Epoch 21/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9736 - accuracy: 0.6440 - val_loss: 0.9773 - val_accuracy: 0.6383 - lr: 9.9958e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0009995382732394672.\n",
      "Epoch 22/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9512 - accuracy: 0.6495 - val_loss: 1.2568 - val_accuracy: 0.5428 - lr: 9.9954e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0009994942501687564.\n",
      "Epoch 23/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.9376 - accuracy: 0.6523 - val_loss: 1.0450 - val_accuracy: 0.6192 - lr: 9.9949e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0009994482483046913.\n",
      "Epoch 24/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.9529 - accuracy: 0.6507 - val_loss: 1.0015 - val_accuracy: 0.6247 - lr: 9.9945e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0009994002676591439.\n",
      "Epoch 25/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.9521 - accuracy: 0.6500 - val_loss: 0.9760 - val_accuracy: 0.6410 - lr: 9.9940e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0009993503082439867.\n",
      "Epoch 26/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.9299 - accuracy: 0.6541 - val_loss: 0.9887 - val_accuracy: 0.6346 - lr: 9.9935e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0009992983700710916.\n",
      "Epoch 27/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9360 - accuracy: 0.6542 - val_loss: 1.0081 - val_accuracy: 0.6336 - lr: 9.9930e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0009992444531523302.\n",
      "Epoch 28/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9277 - accuracy: 0.6552 - val_loss: 0.9063 - val_accuracy: 0.6647 - lr: 9.9924e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0009991884410907716.\n",
      "Epoch 29/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9519 - accuracy: 0.6497 - val_loss: 1.0217 - val_accuracy: 0.6211 - lr: 9.9919e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0009991304503075562.\n",
      "Epoch 30/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9191 - accuracy: 0.6605 - val_loss: 0.9178 - val_accuracy: 0.6569 - lr: 9.9913e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0009990704808145552.\n",
      "Epoch 31/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9129 - accuracy: 0.6623 - val_loss: 0.9028 - val_accuracy: 0.6684 - lr: 9.9907e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009990085326236405.\n",
      "Epoch 32/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9244 - accuracy: 0.6578 - val_loss: 0.8645 - val_accuracy: 0.6839 - lr: 9.9901e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0009989446057466834.\n",
      "Epoch 33/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9203 - accuracy: 0.6597 - val_loss: 0.9071 - val_accuracy: 0.6592 - lr: 9.9894e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0009988787001955555.\n",
      "Epoch 34/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9284 - accuracy: 0.6581 - val_loss: 0.9387 - val_accuracy: 0.6496 - lr: 9.9888e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0009988108159821275.\n",
      "Epoch 35/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.9037 - accuracy: 0.6632 - val_loss: 0.9621 - val_accuracy: 0.6322 - lr: 9.9881e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0009987409531182709.\n",
      "Epoch 36/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.9246 - accuracy: 0.6582 - val_loss: 0.9009 - val_accuracy: 0.6638 - lr: 9.9874e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000998668995208916.\n",
      "Epoch 37/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8913 - accuracy: 0.6705 - val_loss: 0.8608 - val_accuracy: 0.6827 - lr: 9.9867e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0009985950586733404.\n",
      "Epoch 38/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.9030 - accuracy: 0.6652 - val_loss: 0.9559 - val_accuracy: 0.6472 - lr: 9.9860e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0009985191435234143.\n",
      "Epoch 39/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9043 - accuracy: 0.6638 - val_loss: 0.8763 - val_accuracy: 0.6770 - lr: 9.9852e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0009984412497710086.\n",
      "Epoch 40/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8876 - accuracy: 0.6687 - val_loss: 0.8764 - val_accuracy: 0.6737 - lr: 9.9844e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009983613774279944.\n",
      "Epoch 41/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9102 - accuracy: 0.6642 - val_loss: 0.9078 - val_accuracy: 0.6588 - lr: 9.9836e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000998279526506242.\n",
      "Epoch 42/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8962 - accuracy: 0.6669 - val_loss: 0.8523 - val_accuracy: 0.6837 - lr: 9.9828e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009981956970176217.\n",
      "Epoch 43/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8930 - accuracy: 0.6681 - val_loss: 1.1282 - val_accuracy: 0.6022 - lr: 9.9820e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009981098889740038.\n",
      "Epoch 44/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8940 - accuracy: 0.6681 - val_loss: 0.8297 - val_accuracy: 0.6906 - lr: 9.9811e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.000998022102387259.\n",
      "Epoch 45/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.8796 - accuracy: 0.6742 - val_loss: 0.8647 - val_accuracy: 0.6732 - lr: 9.9802e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009979323372692574.\n",
      "Epoch 46/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8934 - accuracy: 0.6684 - val_loss: 0.8825 - val_accuracy: 0.6720 - lr: 9.9793e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000997840593631869.\n",
      "Epoch 47/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8736 - accuracy: 0.6744 - val_loss: 0.9018 - val_accuracy: 0.6624 - lr: 9.9784e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0009977467550825838.\n",
      "Epoch 48/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8757 - accuracy: 0.6752 - val_loss: 0.8618 - val_accuracy: 0.6834 - lr: 9.9775e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0009976509380381173.\n",
      "Epoch 49/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8926 - accuracy: 0.6715 - val_loss: 0.8955 - val_accuracy: 0.6643 - lr: 9.9765e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009975531425103397.\n",
      "Epoch 50/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8802 - accuracy: 0.6729 - val_loss: 1.9120 - val_accuracy: 0.3929 - lr: 9.9755e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0009974533685111198.\n",
      "Epoch 51/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8819 - accuracy: 0.6726 - val_loss: 0.9222 - val_accuracy: 0.6512 - lr: 9.9745e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.000997351616052328.\n",
      "Epoch 52/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8743 - accuracy: 0.6740 - val_loss: 0.8325 - val_accuracy: 0.6943 - lr: 9.9735e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0009972478851458333.\n",
      "Epoch 53/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8678 - accuracy: 0.6777 - val_loss: 0.9079 - val_accuracy: 0.6606 - lr: 9.9725e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0009971421758035056.\n",
      "Epoch 54/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8658 - accuracy: 0.6775 - val_loss: 0.8285 - val_accuracy: 0.6962 - lr: 9.9714e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0009970344880372139.\n",
      "Epoch 55/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8663 - accuracy: 0.6767 - val_loss: 0.8192 - val_accuracy: 0.6931 - lr: 9.9703e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009969248218588275.\n",
      "Epoch 56/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8813 - accuracy: 0.6728 - val_loss: 0.8831 - val_accuracy: 0.6659 - lr: 9.9692e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009968131772802157.\n",
      "Epoch 57/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8535 - accuracy: 0.6813 - val_loss: 0.9250 - val_accuracy: 0.6555 - lr: 9.9681e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009966995543132474.\n",
      "Epoch 58/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8649 - accuracy: 0.6797 - val_loss: 0.8476 - val_accuracy: 0.6853 - lr: 9.9670e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009965839529697913.\n",
      "Epoch 59/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8521 - accuracy: 0.6833 - val_loss: 0.7956 - val_accuracy: 0.6968 - lr: 9.9658e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0009964663732617168.\n",
      "Epoch 60/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8723 - accuracy: 0.6762 - val_loss: 0.8482 - val_accuracy: 0.6824 - lr: 9.9647e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0009963468152008924.\n",
      "Epoch 61/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8576 - accuracy: 0.6803 - val_loss: 0.8449 - val_accuracy: 0.6849 - lr: 9.9635e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0009962252787991868.\n",
      "Epoch 62/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8517 - accuracy: 0.6830 - val_loss: 1.3291 - val_accuracy: 0.5351 - lr: 9.9623e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0009961017640684685.\n",
      "Epoch 63/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8558 - accuracy: 0.6813 - val_loss: 0.8351 - val_accuracy: 0.6907 - lr: 9.9610e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.000995976271020606.\n",
      "Epoch 64/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.8440 - accuracy: 0.6860 - val_loss: 0.8076 - val_accuracy: 0.6989 - lr: 9.9598e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0009958487996674678.\n",
      "Epoch 65/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8539 - accuracy: 0.6806 - val_loss: 0.8586 - val_accuracy: 0.6812 - lr: 9.9585e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.000995719350020922.\n",
      "Epoch 66/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8381 - accuracy: 0.6869 - val_loss: 1.1728 - val_accuracy: 0.5823 - lr: 9.9572e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0009955879220928368.\n",
      "Epoch 67/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8545 - accuracy: 0.6833 - val_loss: 1.0792 - val_accuracy: 0.6079 - lr: 9.9559e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0009954545158950806.\n",
      "Epoch 68/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8379 - accuracy: 0.6874 - val_loss: 0.9836 - val_accuracy: 0.6324 - lr: 9.9545e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.000995319131439521.\n",
      "Epoch 69/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8387 - accuracy: 0.6884 - val_loss: 0.9085 - val_accuracy: 0.6588 - lr: 9.9532e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0009951817687380263.\n",
      "Epoch 70/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8394 - accuracy: 0.6864 - val_loss: 0.8443 - val_accuracy: 0.6853 - lr: 9.9518e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0009950424278024638.\n",
      "Epoch 71/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8450 - accuracy: 0.6843 - val_loss: 0.8621 - val_accuracy: 0.6742 - lr: 9.9504e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0009949011086447018.\n",
      "Epoch 72/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8399 - accuracy: 0.6860 - val_loss: 0.9268 - val_accuracy: 0.6579 - lr: 9.9490e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0009947578112766077.\n",
      "Epoch 73/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8375 - accuracy: 0.6874 - val_loss: 0.7821 - val_accuracy: 0.7020 - lr: 9.9476e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0009946126521083766.\n",
      "Epoch 74/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8239 - accuracy: 0.6891 - val_loss: 0.7891 - val_accuracy: 0.7015 - lr: 9.9461e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0009944655147530828.\n",
      "Epoch 75/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8377 - accuracy: 0.6881 - val_loss: 0.8626 - val_accuracy: 0.6786 - lr: 9.9447e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0009943163992225934.\n",
      "Epoch 76/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8356 - accuracy: 0.6881 - val_loss: 0.8034 - val_accuracy: 0.6966 - lr: 9.9432e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0009941653055287763.\n",
      "Epoch 77/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8225 - accuracy: 0.6921 - val_loss: 0.7955 - val_accuracy: 0.6996 - lr: 9.9417e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0009940122336834982.\n",
      "Epoch 78/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8301 - accuracy: 0.6896 - val_loss: 0.9083 - val_accuracy: 0.6553 - lr: 9.9401e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0009938571836986259.\n",
      "Epoch 79/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8294 - accuracy: 0.6905 - val_loss: 0.8332 - val_accuracy: 0.6894 - lr: 9.9386e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0009937001555860268.\n",
      "Epoch 80/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8176 - accuracy: 0.6935 - val_loss: 0.7815 - val_accuracy: 0.7028 - lr: 9.9370e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0009935411493575677.\n",
      "Epoch 81/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8168 - accuracy: 0.6948 - val_loss: 0.7971 - val_accuracy: 0.7028 - lr: 9.9354e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0009933801650251152.\n",
      "Epoch 82/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8193 - accuracy: 0.6936 - val_loss: 0.7876 - val_accuracy: 0.7065 - lr: 9.9338e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.000993217318996769.\n",
      "Epoch 83/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8138 - accuracy: 0.6969 - val_loss: 0.7783 - val_accuracy: 0.7078 - lr: 9.9322e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0009930524948876971.\n",
      "Epoch 84/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8186 - accuracy: 0.6937 - val_loss: 0.9465 - val_accuracy: 0.6568 - lr: 9.9305e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0009928856927097665.\n",
      "Epoch 85/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8128 - accuracy: 0.6960 - val_loss: 1.0265 - val_accuracy: 0.6270 - lr: 9.9289e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.000992716912474843.\n",
      "Epoch 86/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8193 - accuracy: 0.6927 - val_loss: 0.8132 - val_accuracy: 0.6988 - lr: 9.9272e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.000992546154194793.\n",
      "Epoch 87/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8067 - accuracy: 0.6961 - val_loss: 0.7922 - val_accuracy: 0.6997 - lr: 9.9255e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0009923735342765522.\n",
      "Epoch 88/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8048 - accuracy: 0.6975 - val_loss: 0.7878 - val_accuracy: 0.6998 - lr: 9.9237e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0009921989363364519.\n",
      "Epoch 89/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.8012 - accuracy: 0.6982 - val_loss: 0.7806 - val_accuracy: 0.7072 - lr: 9.9220e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0009920223603863579.\n",
      "Epoch 90/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8120 - accuracy: 0.6962 - val_loss: 0.8529 - val_accuracy: 0.6854 - lr: 9.9202e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0009918438064381362.\n",
      "Epoch 91/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.7983 - accuracy: 0.7011 - val_loss: 0.7689 - val_accuracy: 0.7098 - lr: 9.9184e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.000991663274503653.\n",
      "Epoch 92/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8047 - accuracy: 0.6989 - val_loss: 0.7482 - val_accuracy: 0.7194 - lr: 9.9166e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.000991480880988679.\n",
      "Epoch 93/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7991 - accuracy: 0.6982 - val_loss: 0.7897 - val_accuracy: 0.7015 - lr: 9.9148e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.000991296509510709.\n",
      "Epoch 94/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7961 - accuracy: 0.7013 - val_loss: 0.7849 - val_accuracy: 0.7035 - lr: 9.9130e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0009911101600816087.\n",
      "Epoch 95/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8007 - accuracy: 0.6998 - val_loss: 0.7804 - val_accuracy: 0.7055 - lr: 9.9111e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.000990921832713244.\n",
      "Epoch 96/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8047 - accuracy: 0.6984 - val_loss: 1.1075 - val_accuracy: 0.6063 - lr: 9.9092e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0009907316438104534.\n",
      "Epoch 97/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.8107 - accuracy: 0.6953 - val_loss: 0.8613 - val_accuracy: 0.6719 - lr: 9.9073e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0009905394769916635.\n",
      "Epoch 98/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.8063 - accuracy: 0.6974 - val_loss: 0.7550 - val_accuracy: 0.7145 - lr: 9.9054e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.000990345332268739.\n",
      "Epoch 99/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7845 - accuracy: 0.7055 - val_loss: 0.7494 - val_accuracy: 0.7143 - lr: 9.9035e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.000990149326045821.\n",
      "Epoch 100/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7839 - accuracy: 0.7050 - val_loss: 0.8108 - val_accuracy: 0.6938 - lr: 9.9015e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0009899513419420333.\n",
      "Epoch 101/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7775 - accuracy: 0.7075 - val_loss: 0.8108 - val_accuracy: 0.6968 - lr: 9.8995e-04\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.0009897513799692402.\n",
      "Epoch 102/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7926 - accuracy: 0.7008 - val_loss: 0.7705 - val_accuracy: 0.7073 - lr: 9.8975e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0009895495565308847.\n",
      "Epoch 103/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7742 - accuracy: 0.7092 - val_loss: 0.8978 - val_accuracy: 0.6604 - lr: 9.8955e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.0009893457552467885.\n",
      "Epoch 104/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7977 - accuracy: 0.7042 - val_loss: 0.7368 - val_accuracy: 0.7242 - lr: 9.8935e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0009891399761288154.\n",
      "Epoch 105/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7842 - accuracy: 0.7043 - val_loss: 0.7614 - val_accuracy: 0.7155 - lr: 9.8914e-04\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.0009889323355797102.\n",
      "Epoch 106/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7794 - accuracy: 0.7082 - val_loss: 0.7535 - val_accuracy: 0.7170 - lr: 9.8893e-04\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.000988722717219992.\n",
      "Epoch 107/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7812 - accuracy: 0.7073 - val_loss: 0.7559 - val_accuracy: 0.7124 - lr: 9.8872e-04\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.0009885111210615255.\n",
      "Epoch 108/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7825 - accuracy: 0.7069 - val_loss: 0.7887 - val_accuracy: 0.6993 - lr: 9.8851e-04\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.0009882976635063555.\n",
      "Epoch 109/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7674 - accuracy: 0.7124 - val_loss: 0.9703 - val_accuracy: 0.6541 - lr: 9.8830e-04\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.0009880822281757.\n",
      "Epoch 110/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7845 - accuracy: 0.7067 - val_loss: 0.7992 - val_accuracy: 0.7032 - lr: 9.8808e-04\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.0009878649314711387.\n",
      "Epoch 111/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7740 - accuracy: 0.7107 - val_loss: 0.7149 - val_accuracy: 0.7286 - lr: 9.8786e-04\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.0009876456570143545.\n",
      "Epoch 112/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7608 - accuracy: 0.7144 - val_loss: 0.7993 - val_accuracy: 0.7038 - lr: 9.8765e-04\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.0009874245212064612.\n",
      "Epoch 113/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.9625 - accuracy: 0.6560 - val_loss: 0.8712 - val_accuracy: 0.6787 - lr: 9.8742e-04\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.0009872014076696069.\n",
      "Epoch 114/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.8521 - accuracy: 0.6836 - val_loss: 0.8325 - val_accuracy: 0.6894 - lr: 9.8720e-04\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.0009869764328044406.\n",
      "Epoch 115/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7898 - accuracy: 0.7040 - val_loss: 0.7750 - val_accuracy: 0.7102 - lr: 9.8698e-04\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.0009867494802335748.\n",
      "Epoch 116/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7781 - accuracy: 0.7091 - val_loss: 0.7851 - val_accuracy: 0.7049 - lr: 9.8675e-04\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.0009865205499688732.\n",
      "Epoch 117/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7950 - accuracy: 0.7017 - val_loss: 0.7308 - val_accuracy: 0.7234 - lr: 9.8652e-04\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.0009862897584102862.\n",
      "Epoch 118/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7695 - accuracy: 0.7086 - val_loss: 0.8452 - val_accuracy: 0.6824 - lr: 9.8629e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.000986057105568979.\n",
      "Epoch 119/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7819 - accuracy: 0.7078 - val_loss: 0.7458 - val_accuracy: 0.7165 - lr: 9.8606e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.0009858224750684949.\n",
      "Epoch 120/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7661 - accuracy: 0.7136 - val_loss: 0.7300 - val_accuracy: 0.7215 - lr: 9.8582e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.000985585983308086.\n",
      "Epoch 121/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7550 - accuracy: 0.7152 - val_loss: 0.7422 - val_accuracy: 0.7231 - lr: 9.8559e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.0009853475139117607.\n",
      "Epoch 122/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7720 - accuracy: 0.7104 - val_loss: 0.7082 - val_accuracy: 0.7339 - lr: 9.8535e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.0009851071832783062.\n",
      "Epoch 123/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7526 - accuracy: 0.7167 - val_loss: 0.7941 - val_accuracy: 0.7023 - lr: 9.8511e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.0009848648750321954.\n",
      "Epoch 124/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7607 - accuracy: 0.7142 - val_loss: 0.7137 - val_accuracy: 0.7341 - lr: 9.8486e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.0009846207055717498.\n",
      "Epoch 125/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7646 - accuracy: 0.7111 - val_loss: 0.8436 - val_accuracy: 0.6812 - lr: 9.8462e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.000984374558521908.\n",
      "Epoch 126/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7571 - accuracy: 0.7141 - val_loss: 0.7659 - val_accuracy: 0.7106 - lr: 9.8437e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.0009841265502805259.\n",
      "Epoch 127/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7803 - accuracy: 0.7063 - val_loss: 0.7037 - val_accuracy: 0.7367 - lr: 9.8413e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.000983876680858767.\n",
      "Epoch 128/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7509 - accuracy: 0.7166 - val_loss: 0.7718 - val_accuracy: 0.7077 - lr: 9.8388e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.0009836248338822688.\n",
      "Epoch 129/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7633 - accuracy: 0.7146 - val_loss: 0.9732 - val_accuracy: 0.6381 - lr: 9.8362e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.000983371125748188.\n",
      "Epoch 130/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7426 - accuracy: 0.7187 - val_loss: 0.9369 - val_accuracy: 0.6657 - lr: 9.8337e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.0009831155564676887.\n",
      "Epoch 131/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7730 - accuracy: 0.7127 - val_loss: 0.7864 - val_accuracy: 0.7059 - lr: 9.8312e-04\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.0009828580096671053.\n",
      "Epoch 132/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7432 - accuracy: 0.7195 - val_loss: 0.7638 - val_accuracy: 0.7081 - lr: 9.8286e-04\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.0009825986017428967.\n",
      "Epoch 133/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7425 - accuracy: 0.7197 - val_loss: 0.7197 - val_accuracy: 0.7312 - lr: 9.8260e-04\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.0009823373327062265.\n",
      "Epoch 134/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7490 - accuracy: 0.7183 - val_loss: 0.7055 - val_accuracy: 0.7287 - lr: 9.8234e-04\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.0009820740861841279.\n",
      "Epoch 135/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7595 - accuracy: 0.7132 - val_loss: 0.7606 - val_accuracy: 0.7098 - lr: 9.8207e-04\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.00098180897857236.\n",
      "Epoch 136/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7466 - accuracy: 0.7186 - val_loss: 0.7223 - val_accuracy: 0.7251 - lr: 9.8181e-04\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.0009815420098820864.\n",
      "Epoch 137/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7414 - accuracy: 0.7201 - val_loss: 0.7311 - val_accuracy: 0.7264 - lr: 9.8154e-04\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.000981273180124471.\n",
      "Epoch 138/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7367 - accuracy: 0.7233 - val_loss: 0.9152 - val_accuracy: 0.6673 - lr: 9.8127e-04\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.0009810023729274772.\n",
      "Epoch 139/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7524 - accuracy: 0.7168 - val_loss: 0.7151 - val_accuracy: 0.7325 - lr: 9.8100e-04\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.000980729704685933.\n",
      "Epoch 140/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7440 - accuracy: 0.7205 - val_loss: 0.7952 - val_accuracy: 0.7055 - lr: 9.8073e-04\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.0009804551754110018.\n",
      "Epoch 141/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7501 - accuracy: 0.7171 - val_loss: 0.8179 - val_accuracy: 0.6996 - lr: 9.8046e-04\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.0009801787851138472.\n",
      "Epoch 142/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7373 - accuracy: 0.7213 - val_loss: 1.0577 - val_accuracy: 0.6118 - lr: 9.8018e-04\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.0009799005338056311.\n",
      "Epoch 143/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7385 - accuracy: 0.7220 - val_loss: 0.7173 - val_accuracy: 0.7296 - lr: 9.7990e-04\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.0009796203051154807.\n",
      "Epoch 144/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7334 - accuracy: 0.7236 - val_loss: 0.7782 - val_accuracy: 0.7029 - lr: 9.7962e-04\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.0009793382154370603.\n",
      "Epoch 145/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7408 - accuracy: 0.7213 - val_loss: 0.7199 - val_accuracy: 0.7309 - lr: 9.7934e-04\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.000979054264781533.\n",
      "Epoch 146/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7384 - accuracy: 0.7221 - val_loss: 0.7498 - val_accuracy: 0.7101 - lr: 9.7905e-04\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.000978768453160061.\n",
      "Epoch 147/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7344 - accuracy: 0.7221 - val_loss: 0.6953 - val_accuracy: 0.7365 - lr: 9.7877e-04\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.000978480780583807.\n",
      "Epoch 148/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7313 - accuracy: 0.7237 - val_loss: 0.6982 - val_accuracy: 0.7343 - lr: 9.7848e-04\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.0009781912470639333.\n",
      "Epoch 149/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7302 - accuracy: 0.7265 - val_loss: 0.7337 - val_accuracy: 0.7246 - lr: 9.7819e-04\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.0009778998526116024.\n",
      "Epoch 150/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7578 - accuracy: 0.7157 - val_loss: 0.6894 - val_accuracy: 0.7411 - lr: 9.7790e-04\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.0009776065972379765.\n",
      "Epoch 151/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7157 - accuracy: 0.7289 - val_loss: 0.7618 - val_accuracy: 0.7142 - lr: 9.7761e-04\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.0009773114809542177.\n",
      "Epoch 152/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7273 - accuracy: 0.7269 - val_loss: 0.7458 - val_accuracy: 0.7229 - lr: 9.7731e-04\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.0009770145037714879.\n",
      "Epoch 153/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7245 - accuracy: 0.7268 - val_loss: 0.7584 - val_accuracy: 0.7136 - lr: 9.7701e-04\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.0009767156657009496.\n",
      "Epoch 154/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7229 - accuracy: 0.7257 - val_loss: 0.7598 - val_accuracy: 0.7102 - lr: 9.7672e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.0009764149667537641.\n",
      "Epoch 155/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7254 - accuracy: 0.7268 - val_loss: 0.7344 - val_accuracy: 0.7247 - lr: 9.7641e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.0009761123487514714.\n",
      "Epoch 156/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7372 - accuracy: 0.7207 - val_loss: 0.7662 - val_accuracy: 0.7100 - lr: 9.7611e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.0009758078698950879.\n",
      "Epoch 157/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7270 - accuracy: 0.7275 - val_loss: 0.9350 - val_accuracy: 0.6659 - lr: 9.7581e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.000975501588385165.\n",
      "Epoch 158/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7274 - accuracy: 0.7274 - val_loss: 0.9149 - val_accuracy: 0.6681 - lr: 9.7550e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.0009751934460432415.\n",
      "Epoch 159/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7300 - accuracy: 0.7245 - val_loss: 0.6784 - val_accuracy: 0.7467 - lr: 9.7519e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.0009748834428804792.\n",
      "Epoch 160/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7279 - accuracy: 0.7261 - val_loss: 0.7150 - val_accuracy: 0.7250 - lr: 9.7488e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.0009745715789080395.\n",
      "Epoch 161/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7163 - accuracy: 0.7305 - val_loss: 0.7477 - val_accuracy: 0.7154 - lr: 9.7457e-04\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.0009742578541370837.\n",
      "Epoch 162/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7269 - accuracy: 0.7266 - val_loss: 0.8378 - val_accuracy: 0.6911 - lr: 9.7426e-04\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.0009739422685787726.\n",
      "Epoch 163/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7192 - accuracy: 0.7293 - val_loss: 0.7307 - val_accuracy: 0.7235 - lr: 9.7394e-04\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.000973624880432959.\n",
      "Epoch 164/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7141 - accuracy: 0.7300 - val_loss: 0.6800 - val_accuracy: 0.7419 - lr: 9.7362e-04\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.0009733056315218799.\n",
      "Epoch 165/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7087 - accuracy: 0.7333 - val_loss: 0.6774 - val_accuracy: 0.7431 - lr: 9.7331e-04\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.0009729845218566961.\n",
      "Epoch 166/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7176 - accuracy: 0.7293 - val_loss: 0.7071 - val_accuracy: 0.7319 - lr: 9.7298e-04\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.0009726616096369106.\n",
      "Epoch 167/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7181 - accuracy: 0.7298 - val_loss: 0.6712 - val_accuracy: 0.7480 - lr: 9.7266e-04\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 0.0009723368366851093.\n",
      "Epoch 168/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7141 - accuracy: 0.7303 - val_loss: 0.6444 - val_accuracy: 0.7588 - lr: 9.7234e-04\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 0.0009720102612005626.\n",
      "Epoch 169/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7168 - accuracy: 0.7300 - val_loss: 0.7828 - val_accuracy: 0.7034 - lr: 9.7201e-04\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 0.0009716818250060885.\n",
      "Epoch 170/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7070 - accuracy: 0.7332 - val_loss: 0.6892 - val_accuracy: 0.7416 - lr: 9.7168e-04\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 0.0009713515863007244.\n",
      "Epoch 171/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7300 - accuracy: 0.7246 - val_loss: 0.7410 - val_accuracy: 0.7172 - lr: 9.7135e-04\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 0.0009710194869075212.\n",
      "Epoch 172/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7162 - accuracy: 0.7328 - val_loss: 0.7348 - val_accuracy: 0.7210 - lr: 9.7102e-04\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 0.0009706855850252837.\n",
      "Epoch 173/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6990 - accuracy: 0.7369 - val_loss: 0.6823 - val_accuracy: 0.7429 - lr: 9.7069e-04\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 0.0009703498224772946.\n",
      "Epoch 174/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7048 - accuracy: 0.7336 - val_loss: 0.6696 - val_accuracy: 0.7505 - lr: 9.7035e-04\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 0.0009700122574621261.\n",
      "Epoch 175/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.7089 - accuracy: 0.7328 - val_loss: 0.6997 - val_accuracy: 0.7362 - lr: 9.7001e-04\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 0.0009696728899905889.\n",
      "Epoch 176/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7020 - accuracy: 0.7357 - val_loss: 0.7740 - val_accuracy: 0.7119 - lr: 9.6967e-04\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 0.0009693316618863153.\n",
      "Epoch 177/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7073 - accuracy: 0.7348 - val_loss: 0.6906 - val_accuracy: 0.7394 - lr: 9.6933e-04\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 0.0009689886313475275.\n",
      "Epoch 178/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7300 - accuracy: 0.7272 - val_loss: 0.6969 - val_accuracy: 0.7348 - lr: 9.6899e-04\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 0.0009686437983850364.\n",
      "Epoch 179/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7073 - accuracy: 0.7331 - val_loss: 0.6931 - val_accuracy: 0.7386 - lr: 9.6864e-04\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 0.0009682971630096526.\n",
      "Epoch 180/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7072 - accuracy: 0.7352 - val_loss: 0.6554 - val_accuracy: 0.7505 - lr: 9.6830e-04\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 0.0009679487252321869.\n",
      "Epoch 181/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6926 - accuracy: 0.7394 - val_loss: 0.6479 - val_accuracy: 0.7562 - lr: 9.6795e-04\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 0.0009675984268768521.\n",
      "Epoch 182/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7099 - accuracy: 0.7326 - val_loss: 0.7356 - val_accuracy: 0.7277 - lr: 9.6760e-04\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 0.0009672463261412887.\n",
      "Epoch 183/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6826 - accuracy: 0.7436 - val_loss: 0.7114 - val_accuracy: 0.7327 - lr: 9.6725e-04\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.0009668924230363073.\n",
      "Epoch 184/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7187 - accuracy: 0.7303 - val_loss: 0.6813 - val_accuracy: 0.7409 - lr: 9.6689e-04\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.0009665367175727181.\n",
      "Epoch 185/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7046 - accuracy: 0.7366 - val_loss: 0.7581 - val_accuracy: 0.7192 - lr: 9.6654e-04\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.0009661792097613309.\n",
      "Epoch 186/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6854 - accuracy: 0.7414 - val_loss: 0.6634 - val_accuracy: 0.7513 - lr: 9.6618e-04\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.000965819899612956.\n",
      "Epoch 187/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6877 - accuracy: 0.7423 - val_loss: 0.8428 - val_accuracy: 0.6851 - lr: 9.6582e-04\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.0009654588453243027.\n",
      "Epoch 188/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7041 - accuracy: 0.7353 - val_loss: 0.8689 - val_accuracy: 0.6745 - lr: 9.6546e-04\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.0009650959887200492.\n",
      "Epoch 189/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6994 - accuracy: 0.7339 - val_loss: 0.6580 - val_accuracy: 0.7540 - lr: 9.6510e-04\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.0009647313298110048.\n",
      "Epoch 190/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6904 - accuracy: 0.7397 - val_loss: 0.6637 - val_accuracy: 0.7485 - lr: 9.6473e-04\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.0009643648686079794.\n",
      "Epoch 191/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6840 - accuracy: 0.7431 - val_loss: 0.8099 - val_accuracy: 0.6997 - lr: 9.6436e-04\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.0009639966051217826.\n",
      "Epoch 192/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.7011 - accuracy: 0.7358 - val_loss: 0.6734 - val_accuracy: 0.7439 - lr: 9.6400e-04\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.0009636265975485421.\n",
      "Epoch 193/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6950 - accuracy: 0.7373 - val_loss: 0.6457 - val_accuracy: 0.7567 - lr: 9.6363e-04\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.0009632547877135164.\n",
      "Epoch 194/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7123 - accuracy: 0.7335 - val_loss: 1.1688 - val_accuracy: 0.5930 - lr: 9.6325e-04\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.000962881175627515.\n",
      "Epoch 195/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6922 - accuracy: 0.7379 - val_loss: 0.6631 - val_accuracy: 0.7464 - lr: 9.6288e-04\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.0009625058194863164.\n",
      "Epoch 196/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6842 - accuracy: 0.7423 - val_loss: 0.6524 - val_accuracy: 0.7542 - lr: 9.6251e-04\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.0009621286611155277.\n",
      "Epoch 197/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6897 - accuracy: 0.7411 - val_loss: 0.6296 - val_accuracy: 0.7627 - lr: 9.6213e-04\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.0009617497587106946.\n",
      "Epoch 198/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6838 - accuracy: 0.7415 - val_loss: 0.6662 - val_accuracy: 0.7460 - lr: 9.6175e-04\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.0009613690540976571.\n",
      "Epoch 199/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6781 - accuracy: 0.7433 - val_loss: 0.6379 - val_accuracy: 0.7641 - lr: 9.6137e-04\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.0009609866054717281.\n",
      "Epoch 200/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.7101 - accuracy: 0.7343 - val_loss: 0.8138 - val_accuracy: 0.6962 - lr: 9.6099e-04\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 0.0009606023546589799.\n",
      "Epoch 201/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6928 - accuracy: 0.7379 - val_loss: 0.7189 - val_accuracy: 0.7288 - lr: 9.6060e-04\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 0.0009602163598544921.\n",
      "Epoch 202/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6683 - accuracy: 0.7483 - val_loss: 0.6991 - val_accuracy: 0.7378 - lr: 9.6022e-04\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 0.00095982856288457.\n",
      "Epoch 203/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6986 - accuracy: 0.7380 - val_loss: 0.6676 - val_accuracy: 0.7454 - lr: 9.5983e-04\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 0.0009594390219440608.\n",
      "Epoch 204/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6737 - accuracy: 0.7452 - val_loss: 0.6438 - val_accuracy: 0.7586 - lr: 9.5944e-04\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 0.0009590477370434233.\n",
      "Epoch 205/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6804 - accuracy: 0.7425 - val_loss: 0.6536 - val_accuracy: 0.7526 - lr: 9.5905e-04\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 0.0009586547081931175.\n",
      "Epoch 206/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6815 - accuracy: 0.7430 - val_loss: 0.6706 - val_accuracy: 0.7489 - lr: 9.5865e-04\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 0.0009582598772199134.\n",
      "Epoch 207/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6934 - accuracy: 0.7386 - val_loss: 0.6662 - val_accuracy: 0.7483 - lr: 9.5826e-04\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 0.0009578633023181924.\n",
      "Epoch 208/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6710 - accuracy: 0.7473 - val_loss: 0.6059 - val_accuracy: 0.7685 - lr: 9.5786e-04\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 0.0009574649834984132.\n",
      "Epoch 209/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6868 - accuracy: 0.7411 - val_loss: 0.6413 - val_accuracy: 0.7547 - lr: 9.5746e-04\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 0.0009570649207710355.\n",
      "Epoch 210/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6698 - accuracy: 0.7471 - val_loss: 0.8890 - val_accuracy: 0.6882 - lr: 9.5706e-04\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 0.0009566631141465178.\n",
      "Epoch 211/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6698 - accuracy: 0.7453 - val_loss: 0.8643 - val_accuracy: 0.6802 - lr: 9.5666e-04\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 0.0009562595636353198.\n",
      "Epoch 212/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6760 - accuracy: 0.7429 - val_loss: 0.6397 - val_accuracy: 0.7579 - lr: 9.5626e-04\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 0.0009558542692478996.\n",
      "Epoch 213/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6745 - accuracy: 0.7437 - val_loss: 0.7735 - val_accuracy: 0.7110 - lr: 9.5585e-04\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 0.0009554472309947165.\n",
      "Epoch 214/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6733 - accuracy: 0.7464 - val_loss: 0.7003 - val_accuracy: 0.7330 - lr: 9.5545e-04\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 0.000955038448886229.\n",
      "Epoch 215/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6875 - accuracy: 0.7398 - val_loss: 0.6835 - val_accuracy: 0.7435 - lr: 9.5504e-04\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 0.0009546279811155384.\n",
      "Epoch 216/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6540 - accuracy: 0.7531 - val_loss: 0.6393 - val_accuracy: 0.7569 - lr: 9.5463e-04\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 0.0009542157695102278.\n",
      "Epoch 217/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6762 - accuracy: 0.7468 - val_loss: 0.6044 - val_accuracy: 0.7686 - lr: 9.5422e-04\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 0.0009538018140807559.\n",
      "Epoch 218/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6785 - accuracy: 0.7436 - val_loss: 0.6823 - val_accuracy: 0.7440 - lr: 9.5380e-04\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 0.0009533861148375813.\n",
      "Epoch 219/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6633 - accuracy: 0.7498 - val_loss: 0.7244 - val_accuracy: 0.7273 - lr: 9.5339e-04\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 0.0009529687299733392.\n",
      "Epoch 220/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6786 - accuracy: 0.7441 - val_loss: 0.7023 - val_accuracy: 0.7336 - lr: 9.5297e-04\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 0.0009525496013160779.\n",
      "Epoch 221/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6586 - accuracy: 0.7515 - val_loss: 0.6286 - val_accuracy: 0.7611 - lr: 9.5255e-04\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 0.0009521287870582002.\n",
      "Epoch 222/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6540 - accuracy: 0.7523 - val_loss: 0.6464 - val_accuracy: 0.7520 - lr: 9.5213e-04\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 0.0009517062290279871.\n",
      "Epoch 223/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6531 - accuracy: 0.7515 - val_loss: 0.6572 - val_accuracy: 0.7492 - lr: 9.5171e-04\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 0.0009512819854176085.\n",
      "Epoch 224/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6767 - accuracy: 0.7445 - val_loss: 0.6539 - val_accuracy: 0.7508 - lr: 9.5128e-04\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 0.0009508559980555775.\n",
      "Epoch 225/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6642 - accuracy: 0.7498 - val_loss: 0.6903 - val_accuracy: 0.7389 - lr: 9.5086e-04\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 0.0009504283251338314.\n",
      "Epoch 226/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6717 - accuracy: 0.7454 - val_loss: 0.6110 - val_accuracy: 0.7676 - lr: 9.5043e-04\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 0.0009499989084811163.\n",
      "Epoch 227/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6555 - accuracy: 0.7532 - val_loss: 0.6568 - val_accuracy: 0.7502 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 0.0009495678062891357.\n",
      "Epoch 228/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6785 - accuracy: 0.7439 - val_loss: 0.6122 - val_accuracy: 0.7684 - lr: 9.4957e-04\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 0.0009491350185679987.\n",
      "Epoch 229/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6590 - accuracy: 0.7502 - val_loss: 0.5817 - val_accuracy: 0.7801 - lr: 9.4913e-04\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 0.0009487004871467999.\n",
      "Epoch 230/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6506 - accuracy: 0.7539 - val_loss: 0.6793 - val_accuracy: 0.7437 - lr: 9.4870e-04\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 0.0009482642702168945.\n",
      "Epoch 231/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6696 - accuracy: 0.7474 - val_loss: 0.5923 - val_accuracy: 0.7779 - lr: 9.4826e-04\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 0.0009478263677883905.\n",
      "Epoch 232/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6755 - accuracy: 0.7467 - val_loss: 0.8369 - val_accuracy: 0.6867 - lr: 9.4783e-04\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 0.0009473867798713963.\n",
      "Epoch 233/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6705 - accuracy: 0.7471 - val_loss: 0.6137 - val_accuracy: 0.7686 - lr: 9.4739e-04\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 0.0009469455064760202.\n",
      "Epoch 234/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6655 - accuracy: 0.7490 - val_loss: 0.6549 - val_accuracy: 0.7517 - lr: 9.4695e-04\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 0.0009465025476123707.\n",
      "Epoch 235/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6498 - accuracy: 0.7551 - val_loss: 0.6283 - val_accuracy: 0.7587 - lr: 9.4650e-04\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 0.0009460579032905551.\n",
      "Epoch 236/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6699 - accuracy: 0.7477 - val_loss: 0.6189 - val_accuracy: 0.7684 - lr: 9.4606e-04\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 0.000945611573520682.\n",
      "Epoch 237/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6398 - accuracy: 0.7594 - val_loss: 0.6410 - val_accuracy: 0.7551 - lr: 9.4561e-04\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 0.0009451635583128589.\n",
      "Epoch 238/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6583 - accuracy: 0.7518 - val_loss: 0.8136 - val_accuracy: 0.7036 - lr: 9.4516e-04\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 0.000944713857677194.\n",
      "Epoch 239/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6543 - accuracy: 0.7511 - val_loss: 0.6087 - val_accuracy: 0.7690 - lr: 9.4471e-04\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 0.0009442624716237947.\n",
      "Epoch 240/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6481 - accuracy: 0.7561 - val_loss: 0.6448 - val_accuracy: 0.7505 - lr: 9.4426e-04\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 0.0009438094583425034.\n",
      "Epoch 241/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6625 - accuracy: 0.7499 - val_loss: 0.6536 - val_accuracy: 0.7549 - lr: 9.4381e-04\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 0.0009433547596634604.\n",
      "Epoch 242/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6530 - accuracy: 0.7536 - val_loss: 0.6607 - val_accuracy: 0.7474 - lr: 9.4335e-04\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 0.0009428983755967735.\n",
      "Epoch 243/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6501 - accuracy: 0.7545 - val_loss: 0.7047 - val_accuracy: 0.7369 - lr: 9.4290e-04\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 0.0009424403643319354.\n",
      "Epoch 244/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6387 - accuracy: 0.7578 - val_loss: 0.6176 - val_accuracy: 0.7624 - lr: 9.4244e-04\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 0.0009419806676994353.\n",
      "Epoch 245/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6739 - accuracy: 0.7470 - val_loss: 0.6664 - val_accuracy: 0.7469 - lr: 9.4198e-04\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 0.0009415193438885335.\n",
      "Epoch 246/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6511 - accuracy: 0.7553 - val_loss: 0.6271 - val_accuracy: 0.7643 - lr: 9.4152e-04\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 0.0009410563347299518.\n",
      "Epoch 247/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6403 - accuracy: 0.7578 - val_loss: 0.6713 - val_accuracy: 0.7502 - lr: 9.4106e-04\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 0.0009405916984127173.\n",
      "Epoch 248/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6435 - accuracy: 0.7567 - val_loss: 0.6305 - val_accuracy: 0.7623 - lr: 9.4059e-04\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 0.0009401253767677841.\n",
      "Epoch 249/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6452 - accuracy: 0.7555 - val_loss: 0.6268 - val_accuracy: 0.7712 - lr: 9.4013e-04\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 0.000939657427983947.\n",
      "Epoch 250/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6640 - accuracy: 0.7501 - val_loss: 0.6142 - val_accuracy: 0.7707 - lr: 9.3966e-04\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 0.0009391878520709643.\n",
      "Epoch 251/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6354 - accuracy: 0.7572 - val_loss: 0.6174 - val_accuracy: 0.7619 - lr: 9.3919e-04\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 0.0009387165908601381.\n",
      "Epoch 252/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6464 - accuracy: 0.7564 - val_loss: 0.6255 - val_accuracy: 0.7649 - lr: 9.3872e-04\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 0.0009382437025399143.\n",
      "Epoch 253/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6483 - accuracy: 0.7545 - val_loss: 0.7894 - val_accuracy: 0.7111 - lr: 9.3824e-04\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 0.0009377691871200508.\n",
      "Epoch 254/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6484 - accuracy: 0.7560 - val_loss: 0.7344 - val_accuracy: 0.7238 - lr: 9.3777e-04\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 0.0009372930446103049.\n",
      "Epoch 255/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6633 - accuracy: 0.7506 - val_loss: 0.6602 - val_accuracy: 0.7507 - lr: 9.3729e-04\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 0.0009368152750204343.\n",
      "Epoch 256/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6399 - accuracy: 0.7578 - val_loss: 0.6440 - val_accuracy: 0.7528 - lr: 9.3682e-04\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 0.0009363358783601965.\n",
      "Epoch 257/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6362 - accuracy: 0.7599 - val_loss: 0.6297 - val_accuracy: 0.7578 - lr: 9.3634e-04\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 0.000935854854639349.\n",
      "Epoch 258/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6545 - accuracy: 0.7519 - val_loss: 0.5840 - val_accuracy: 0.7841 - lr: 9.3585e-04\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 0.0009353722038676491.\n",
      "Epoch 259/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6363 - accuracy: 0.7615 - val_loss: 0.6445 - val_accuracy: 0.7552 - lr: 9.3537e-04\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 0.0009348879260548538.\n",
      "Epoch 260/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6517 - accuracy: 0.7530 - val_loss: 0.7641 - val_accuracy: 0.7184 - lr: 9.3489e-04\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 0.0009344020212107205.\n",
      "Epoch 261/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6320 - accuracy: 0.7617 - val_loss: 0.7345 - val_accuracy: 0.7236 - lr: 9.3440e-04\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 0.0009339144893450066.\n",
      "Epoch 262/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6470 - accuracy: 0.7568 - val_loss: 0.6103 - val_accuracy: 0.7676 - lr: 9.3391e-04\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 0.0009334253886446446.\n",
      "Epoch 263/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6412 - accuracy: 0.7589 - val_loss: 0.6271 - val_accuracy: 0.7624 - lr: 9.3343e-04\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 0.000932934660941983.\n",
      "Epoch 264/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6269 - accuracy: 0.7613 - val_loss: 0.8573 - val_accuracy: 0.6920 - lr: 9.3293e-04\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 0.0009324423062467786.\n",
      "Epoch 265/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6287 - accuracy: 0.7611 - val_loss: 0.6480 - val_accuracy: 0.7584 - lr: 9.3244e-04\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 0.0009319483827456157.\n",
      "Epoch 266/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6223 - accuracy: 0.7629 - val_loss: 0.6387 - val_accuracy: 0.7566 - lr: 9.3195e-04\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 0.0009314528322711909.\n",
      "Epoch 267/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6457 - accuracy: 0.7574 - val_loss: 0.5890 - val_accuracy: 0.7800 - lr: 9.3145e-04\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 0.0009309557130098556.\n",
      "Epoch 268/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6305 - accuracy: 0.7612 - val_loss: 0.5706 - val_accuracy: 0.7845 - lr: 9.3096e-04\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 0.0009304569667945389.\n",
      "Epoch 269/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6373 - accuracy: 0.7592 - val_loss: 0.7044 - val_accuracy: 0.7376 - lr: 9.3046e-04\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 0.0009299566518113599.\n",
      "Epoch 270/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6579 - accuracy: 0.7498 - val_loss: 0.6576 - val_accuracy: 0.7498 - lr: 9.2996e-04\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 0.0009294547680697255.\n",
      "Epoch 271/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6346 - accuracy: 0.7625 - val_loss: 0.5905 - val_accuracy: 0.7808 - lr: 9.2945e-04\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 0.0009289512574029139.\n",
      "Epoch 272/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6241 - accuracy: 0.7633 - val_loss: 0.5782 - val_accuracy: 0.7800 - lr: 9.2895e-04\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 0.0009284461779966945.\n",
      "Epoch 273/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6268 - accuracy: 0.7626 - val_loss: 0.5767 - val_accuracy: 0.7805 - lr: 9.2845e-04\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 0.0009279395298604749.\n",
      "Epoch 274/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6221 - accuracy: 0.7630 - val_loss: 0.6908 - val_accuracy: 0.7404 - lr: 9.2794e-04\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 0.0009274313130036618.\n",
      "Epoch 275/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6387 - accuracy: 0.7587 - val_loss: 0.5893 - val_accuracy: 0.7744 - lr: 9.2743e-04\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 0.0009269215274356627.\n",
      "Epoch 276/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6213 - accuracy: 0.7637 - val_loss: 0.8225 - val_accuracy: 0.7075 - lr: 9.2692e-04\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 0.0009264101731658845.\n",
      "Epoch 277/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6462 - accuracy: 0.7561 - val_loss: 0.6035 - val_accuracy: 0.7682 - lr: 9.2641e-04\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 0.0009258972502037345.\n",
      "Epoch 278/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6404 - accuracy: 0.7593 - val_loss: 0.6447 - val_accuracy: 0.7607 - lr: 9.2590e-04\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 0.0009253827585586193.\n",
      "Epoch 279/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6275 - accuracy: 0.7625 - val_loss: 0.9758 - val_accuracy: 0.6707 - lr: 9.2538e-04\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 0.0009248666982399458.\n",
      "Epoch 280/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6508 - accuracy: 0.7559 - val_loss: 0.5857 - val_accuracy: 0.7771 - lr: 9.2487e-04\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 0.0009243490692571211.\n",
      "Epoch 281/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6243 - accuracy: 0.7641 - val_loss: 0.6176 - val_accuracy: 0.7657 - lr: 9.2435e-04\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 0.0009238298716195513.\n",
      "Epoch 282/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6104 - accuracy: 0.7696 - val_loss: 0.6165 - val_accuracy: 0.7651 - lr: 9.2383e-04\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 0.0009233091053366435.\n",
      "Epoch 283/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6304 - accuracy: 0.7627 - val_loss: 0.7678 - val_accuracy: 0.7161 - lr: 9.2331e-04\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 0.000922786828592538.\n",
      "Epoch 284/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6124 - accuracy: 0.7692 - val_loss: 0.6044 - val_accuracy: 0.7718 - lr: 9.2279e-04\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 0.0009222629832216751.\n",
      "Epoch 285/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6356 - accuracy: 0.7595 - val_loss: 0.7048 - val_accuracy: 0.7379 - lr: 9.2226e-04\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 0.0009217375692334607.\n",
      "Epoch 286/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6283 - accuracy: 0.7622 - val_loss: 0.5861 - val_accuracy: 0.7786 - lr: 9.2174e-04\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 0.0009212106448116865.\n",
      "Epoch 287/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6107 - accuracy: 0.7700 - val_loss: 0.6948 - val_accuracy: 0.7386 - lr: 9.2121e-04\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 0.000920682151791141.\n",
      "Epoch 288/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6663 - accuracy: 0.7520 - val_loss: 0.6147 - val_accuracy: 0.7706 - lr: 9.2068e-04\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 0.0009201521483553831.\n",
      "Epoch 289/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6056 - accuracy: 0.7706 - val_loss: 0.5906 - val_accuracy: 0.7780 - lr: 9.2015e-04\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 0.0009196206345134699.\n",
      "Epoch 290/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6105 - accuracy: 0.7706 - val_loss: 0.6134 - val_accuracy: 0.7663 - lr: 9.1962e-04\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 0.0009190875521005385.\n",
      "Epoch 291/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6334 - accuracy: 0.7620 - val_loss: 0.9723 - val_accuracy: 0.6596 - lr: 9.1909e-04\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 0.0009185529592997988.\n",
      "Epoch 292/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6289 - accuracy: 0.7630 - val_loss: 0.6082 - val_accuracy: 0.7688 - lr: 9.1855e-04\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 0.0009180168561203078.\n",
      "Epoch 293/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6068 - accuracy: 0.7690 - val_loss: 0.6443 - val_accuracy: 0.7542 - lr: 9.1802e-04\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 0.0009174791843975512.\n",
      "Epoch 294/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6102 - accuracy: 0.7690 - val_loss: 0.6304 - val_accuracy: 0.7635 - lr: 9.1748e-04\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 0.0009169400023143896.\n",
      "Epoch 295/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6106 - accuracy: 0.7683 - val_loss: 0.6554 - val_accuracy: 0.7517 - lr: 9.1694e-04\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 0.0009163993098798797.\n",
      "Epoch 296/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6200 - accuracy: 0.7652 - val_loss: 0.6181 - val_accuracy: 0.7640 - lr: 9.1640e-04\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 0.0009158571071030787.\n",
      "Epoch 297/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6155 - accuracy: 0.7681 - val_loss: 0.6776 - val_accuracy: 0.7479 - lr: 9.1586e-04\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 0.0009153133939930429.\n",
      "Epoch 298/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6096 - accuracy: 0.7672 - val_loss: 0.5859 - val_accuracy: 0.7806 - lr: 9.1531e-04\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 0.000914768170558829.\n",
      "Epoch 299/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6106 - accuracy: 0.7694 - val_loss: 0.6014 - val_accuracy: 0.7693 - lr: 9.1477e-04\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 0.000914221494982367.\n",
      "Epoch 300/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6483 - accuracy: 0.7556 - val_loss: 0.6400 - val_accuracy: 0.7588 - lr: 9.1422e-04\n",
      "\n",
      "Epoch 301: LearningRateScheduler setting learning rate to 0.0009136733090996076.\n",
      "Epoch 301/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6123 - accuracy: 0.7687 - val_loss: 0.7572 - val_accuracy: 0.7199 - lr: 9.1367e-04\n",
      "\n",
      "Epoch 302: LearningRateScheduler setting learning rate to 0.0009131236129196066.\n",
      "Epoch 302/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5978 - accuracy: 0.7725 - val_loss: 0.5918 - val_accuracy: 0.7748 - lr: 9.1312e-04\n",
      "\n",
      "Epoch 303: LearningRateScheduler setting learning rate to 0.0009125724064514208.\n",
      "Epoch 303/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6172 - accuracy: 0.7667 - val_loss: 0.6609 - val_accuracy: 0.7530 - lr: 9.1257e-04\n",
      "\n",
      "Epoch 304: LearningRateScheduler setting learning rate to 0.0009120197478765145.\n",
      "Epoch 304/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6327 - accuracy: 0.7595 - val_loss: 0.5855 - val_accuracy: 0.7789 - lr: 9.1202e-04\n",
      "\n",
      "Epoch 305: LearningRateScheduler setting learning rate to 0.0009114655790313035.\n",
      "Epoch 305/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6171 - accuracy: 0.7684 - val_loss: 0.6116 - val_accuracy: 0.7690 - lr: 9.1147e-04\n",
      "\n",
      "Epoch 306: LearningRateScheduler setting learning rate to 0.0009109098999248432.\n",
      "Epoch 306/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6101 - accuracy: 0.7686 - val_loss: 0.5952 - val_accuracy: 0.7746 - lr: 9.1091e-04\n",
      "\n",
      "Epoch 307: LearningRateScheduler setting learning rate to 0.0009103527687382495.\n",
      "Epoch 307/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6150 - accuracy: 0.7683 - val_loss: 0.5633 - val_accuracy: 0.7885 - lr: 9.1035e-04\n",
      "\n",
      "Epoch 308: LearningRateScheduler setting learning rate to 0.0009097941273082864.\n",
      "Epoch 308/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6054 - accuracy: 0.7703 - val_loss: 0.6207 - val_accuracy: 0.7633 - lr: 9.0979e-04\n",
      "\n",
      "Epoch 309: LearningRateScheduler setting learning rate to 0.0009092340338158366.\n",
      "Epoch 309/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6370 - accuracy: 0.7617 - val_loss: 0.7315 - val_accuracy: 0.7234 - lr: 9.0923e-04\n",
      "\n",
      "Epoch 310: LearningRateScheduler setting learning rate to 0.0009086724882696071.\n",
      "Epoch 310/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6155 - accuracy: 0.7671 - val_loss: 0.8080 - val_accuracy: 0.7071 - lr: 9.0867e-04\n",
      "\n",
      "Epoch 311: LearningRateScheduler setting learning rate to 0.0009081094325067104.\n",
      "Epoch 311/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6119 - accuracy: 0.7691 - val_loss: 0.6677 - val_accuracy: 0.7503 - lr: 9.0811e-04\n",
      "\n",
      "Epoch 312: LearningRateScheduler setting learning rate to 0.0009075449247076806.\n",
      "Epoch 312/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6116 - accuracy: 0.7706 - val_loss: 0.5762 - val_accuracy: 0.7832 - lr: 9.0754e-04\n",
      "\n",
      "Epoch 313: LearningRateScheduler setting learning rate to 0.000906978964881224.\n",
      "Epoch 313/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5975 - accuracy: 0.7735 - val_loss: 0.5703 - val_accuracy: 0.7826 - lr: 9.0698e-04\n",
      "\n",
      "Epoch 314: LearningRateScheduler setting learning rate to 0.0009064115530360476.\n",
      "Epoch 314/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6012 - accuracy: 0.7705 - val_loss: 0.6839 - val_accuracy: 0.7452 - lr: 9.0641e-04\n",
      "\n",
      "Epoch 315: LearningRateScheduler setting learning rate to 0.000905842689180858.\n",
      "Epoch 315/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6152 - accuracy: 0.7668 - val_loss: 0.5952 - val_accuracy: 0.7727 - lr: 9.0584e-04\n",
      "\n",
      "Epoch 316: LearningRateScheduler setting learning rate to 0.0009052723733243621.\n",
      "Epoch 316/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6192 - accuracy: 0.7674 - val_loss: 0.6133 - val_accuracy: 0.7677 - lr: 9.0527e-04\n",
      "\n",
      "Epoch 317: LearningRateScheduler setting learning rate to 0.0009047006054752659.\n",
      "Epoch 317/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6042 - accuracy: 0.7708 - val_loss: 0.5711 - val_accuracy: 0.7830 - lr: 9.0470e-04\n",
      "\n",
      "Epoch 318: LearningRateScheduler setting learning rate to 0.000904127385642276.\n",
      "Epoch 318/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6184 - accuracy: 0.7688 - val_loss: 0.5738 - val_accuracy: 0.7841 - lr: 9.0413e-04\n",
      "\n",
      "Epoch 319: LearningRateScheduler setting learning rate to 0.0009035527138340989.\n",
      "Epoch 319/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5970 - accuracy: 0.7735 - val_loss: 0.5986 - val_accuracy: 0.7678 - lr: 9.0355e-04\n",
      "\n",
      "Epoch 320: LearningRateScheduler setting learning rate to 0.0009029765900594409.\n",
      "Epoch 320/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5929 - accuracy: 0.7746 - val_loss: 0.5733 - val_accuracy: 0.7821 - lr: 9.0298e-04\n",
      "\n",
      "Epoch 321: LearningRateScheduler setting learning rate to 0.0009023990724974398.\n",
      "Epoch 321/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5967 - accuracy: 0.7757 - val_loss: 0.6052 - val_accuracy: 0.7721 - lr: 9.0240e-04\n",
      "\n",
      "Epoch 322: LearningRateScheduler setting learning rate to 0.0009018201029861376.\n",
      "Epoch 322/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6050 - accuracy: 0.7718 - val_loss: 0.5687 - val_accuracy: 0.7869 - lr: 9.0182e-04\n",
      "\n",
      "Epoch 323: LearningRateScheduler setting learning rate to 0.0009012396815342404.\n",
      "Epoch 323/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5965 - accuracy: 0.7750 - val_loss: 0.6140 - val_accuracy: 0.7643 - lr: 9.0124e-04\n",
      "\n",
      "Epoch 324: LearningRateScheduler setting learning rate to 0.0009006578663205372.\n",
      "Epoch 324/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5930 - accuracy: 0.7754 - val_loss: 0.6863 - val_accuracy: 0.7454 - lr: 9.0066e-04\n",
      "\n",
      "Epoch 325: LearningRateScheduler setting learning rate to 0.0009000745991834184.\n",
      "Epoch 325/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6249 - accuracy: 0.7654 - val_loss: 0.7022 - val_accuracy: 0.7372 - lr: 9.0007e-04\n",
      "\n",
      "Epoch 326: LearningRateScheduler setting learning rate to 0.0008994899383014404.\n",
      "Epoch 326/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.6021 - accuracy: 0.7711 - val_loss: 0.6000 - val_accuracy: 0.7721 - lr: 8.9949e-04\n",
      "\n",
      "Epoch 327: LearningRateScheduler setting learning rate to 0.0008989038255132259.\n",
      "Epoch 327/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6077 - accuracy: 0.7705 - val_loss: 0.5454 - val_accuracy: 0.7935 - lr: 8.9890e-04\n",
      "\n",
      "Epoch 328: LearningRateScheduler setting learning rate to 0.0008983163189970988.\n",
      "Epoch 328/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5842 - accuracy: 0.7788 - val_loss: 0.7656 - val_accuracy: 0.7195 - lr: 8.9832e-04\n",
      "\n",
      "Epoch 329: LearningRateScheduler setting learning rate to 0.0008977274187614157.\n",
      "Epoch 329/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6665 - accuracy: 0.7546 - val_loss: 1.0694 - val_accuracy: 0.6483 - lr: 8.9773e-04\n",
      "\n",
      "Epoch 330: LearningRateScheduler setting learning rate to 0.0008971371248145337.\n",
      "Epoch 330/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5999 - accuracy: 0.7727 - val_loss: 0.5944 - val_accuracy: 0.7745 - lr: 8.9714e-04\n",
      "\n",
      "Epoch 331: LearningRateScheduler setting learning rate to 0.0008965453789955401.\n",
      "Epoch 331/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5836 - accuracy: 0.7785 - val_loss: 0.5269 - val_accuracy: 0.8017 - lr: 8.9655e-04\n",
      "\n",
      "Epoch 332: LearningRateScheduler setting learning rate to 0.0008959522394822938.\n",
      "Epoch 332/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5865 - accuracy: 0.7782 - val_loss: 0.7094 - val_accuracy: 0.7374 - lr: 8.9595e-04\n",
      "\n",
      "Epoch 333: LearningRateScheduler setting learning rate to 0.0008953577062831507.\n",
      "Epoch 333/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6083 - accuracy: 0.7701 - val_loss: 0.5470 - val_accuracy: 0.7917 - lr: 8.9536e-04\n",
      "\n",
      "Epoch 334: LearningRateScheduler setting learning rate to 0.0008947617794064679.\n",
      "Epoch 334/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5965 - accuracy: 0.7749 - val_loss: 0.6961 - val_accuracy: 0.7367 - lr: 8.9476e-04\n",
      "\n",
      "Epoch 335: LearningRateScheduler setting learning rate to 0.0008941644588606017.\n",
      "Epoch 335/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5775 - accuracy: 0.7807 - val_loss: 0.5706 - val_accuracy: 0.7804 - lr: 8.9416e-04\n",
      "\n",
      "Epoch 336: LearningRateScheduler setting learning rate to 0.0008935657446539084.\n",
      "Epoch 336/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6028 - accuracy: 0.7724 - val_loss: 0.5745 - val_accuracy: 0.7867 - lr: 8.9357e-04\n",
      "\n",
      "Epoch 337: LearningRateScheduler setting learning rate to 0.0008929656949633162.\n",
      "Epoch 337/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5953 - accuracy: 0.7741 - val_loss: 0.6127 - val_accuracy: 0.7678 - lr: 8.9297e-04\n",
      "\n",
      "Epoch 338: LearningRateScheduler setting learning rate to 0.000892364251628377.\n",
      "Epoch 338/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6082 - accuracy: 0.7718 - val_loss: 0.6361 - val_accuracy: 0.7612 - lr: 8.9236e-04\n",
      "\n",
      "Epoch 339: LearningRateScheduler setting learning rate to 0.0008917614146574473.\n",
      "Epoch 339/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5991 - accuracy: 0.7735 - val_loss: 0.5671 - val_accuracy: 0.7875 - lr: 8.9176e-04\n",
      "\n",
      "Epoch 340: LearningRateScheduler setting learning rate to 0.000891157184058883.\n",
      "Epoch 340/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5957 - accuracy: 0.7750 - val_loss: 0.5391 - val_accuracy: 0.7968 - lr: 8.9116e-04\n",
      "\n",
      "Epoch 341: LearningRateScheduler setting learning rate to 0.0008905516180091468.\n",
      "Epoch 341/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5788 - accuracy: 0.7809 - val_loss: 0.5970 - val_accuracy: 0.7692 - lr: 8.9055e-04\n",
      "\n",
      "Epoch 342: LearningRateScheduler setting learning rate to 0.0008899446583482558.\n",
      "Epoch 342/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6446 - accuracy: 0.7599 - val_loss: 0.5400 - val_accuracy: 0.7960 - lr: 8.8994e-04\n",
      "\n",
      "Epoch 343: LearningRateScheduler setting learning rate to 0.0008893363632524401.\n",
      "Epoch 343/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5713 - accuracy: 0.7832 - val_loss: 0.5586 - val_accuracy: 0.7921 - lr: 8.8934e-04\n",
      "\n",
      "Epoch 344: LearningRateScheduler setting learning rate to 0.0008887266745619486.\n",
      "Epoch 344/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5707 - accuracy: 0.7861 - val_loss: 0.5961 - val_accuracy: 0.7769 - lr: 8.8873e-04\n",
      "\n",
      "Epoch 345: LearningRateScheduler setting learning rate to 0.0008881156504527789.\n",
      "Epoch 345/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6023 - accuracy: 0.7734 - val_loss: 0.5265 - val_accuracy: 0.7991 - lr: 8.8812e-04\n",
      "\n",
      "Epoch 346: LearningRateScheduler setting learning rate to 0.0008875032909329379.\n",
      "Epoch 346/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.6018 - accuracy: 0.7718 - val_loss: 0.5866 - val_accuracy: 0.7780 - lr: 8.8750e-04\n",
      "\n",
      "Epoch 347: LearningRateScheduler setting learning rate to 0.0008868895378430238.\n",
      "Epoch 347/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5708 - accuracy: 0.7829 - val_loss: 0.5171 - val_accuracy: 0.8024 - lr: 8.8689e-04\n",
      "\n",
      "Epoch 348: LearningRateScheduler setting learning rate to 0.0008862744493586846.\n",
      "Epoch 348/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5851 - accuracy: 0.7791 - val_loss: 0.5529 - val_accuracy: 0.7935 - lr: 8.8627e-04\n",
      "\n",
      "Epoch 349: LearningRateScheduler setting learning rate to 0.0008856580254879273.\n",
      "Epoch 349/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5705 - accuracy: 0.7838 - val_loss: 0.6251 - val_accuracy: 0.7660 - lr: 8.8566e-04\n",
      "\n",
      "Epoch 350: LearningRateScheduler setting learning rate to 0.0008850402662387586.\n",
      "Epoch 350/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5996 - accuracy: 0.7750 - val_loss: 0.5579 - val_accuracy: 0.7874 - lr: 8.8504e-04\n",
      "\n",
      "Epoch 351: LearningRateScheduler setting learning rate to 0.0008844211716191853.\n",
      "Epoch 351/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5753 - accuracy: 0.7814 - val_loss: 0.5521 - val_accuracy: 0.7908 - lr: 8.8442e-04\n",
      "\n",
      "Epoch 352: LearningRateScheduler setting learning rate to 0.0008838007416372137.\n",
      "Epoch 352/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5774 - accuracy: 0.7806 - val_loss: 0.5472 - val_accuracy: 0.7925 - lr: 8.8380e-04\n",
      "\n",
      "Epoch 353: LearningRateScheduler setting learning rate to 0.0008831789763008506.\n",
      "Epoch 353/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5819 - accuracy: 0.7803 - val_loss: 0.5567 - val_accuracy: 0.7924 - lr: 8.8318e-04\n",
      "\n",
      "Epoch 354: LearningRateScheduler setting learning rate to 0.0008825558756181023.\n",
      "Epoch 354/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.6097 - accuracy: 0.7716 - val_loss: 0.5947 - val_accuracy: 0.7773 - lr: 8.8256e-04\n",
      "\n",
      "Epoch 355: LearningRateScheduler setting learning rate to 0.0008819314395969754.\n",
      "Epoch 355/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5873 - accuracy: 0.7789 - val_loss: 0.5881 - val_accuracy: 0.7762 - lr: 8.8193e-04\n",
      "\n",
      "Epoch 356: LearningRateScheduler setting learning rate to 0.0008813057264118389.\n",
      "Epoch 356/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5794 - accuracy: 0.7806 - val_loss: 0.5179 - val_accuracy: 0.8056 - lr: 8.8131e-04\n",
      "\n",
      "Epoch 357: LearningRateScheduler setting learning rate to 0.0008806786779041037.\n",
      "Epoch 357/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5773 - accuracy: 0.7831 - val_loss: 0.5482 - val_accuracy: 0.7923 - lr: 8.8068e-04\n",
      "\n",
      "Epoch 358: LearningRateScheduler setting learning rate to 0.0008800502940817762.\n",
      "Epoch 358/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5833 - accuracy: 0.7790 - val_loss: 0.5761 - val_accuracy: 0.7840 - lr: 8.8005e-04\n",
      "\n",
      "Epoch 359: LearningRateScheduler setting learning rate to 0.0008794206331188768.\n",
      "Epoch 359/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5687 - accuracy: 0.7846 - val_loss: 0.5668 - val_accuracy: 0.7830 - lr: 8.7942e-04\n",
      "\n",
      "Epoch 360: LearningRateScheduler setting learning rate to 0.0008787896368571645.\n",
      "Epoch 360/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5674 - accuracy: 0.7871 - val_loss: 1.3517 - val_accuracy: 0.5999 - lr: 8.7879e-04\n",
      "\n",
      "Epoch 361: LearningRateScheduler setting learning rate to 0.0008781573634704272.\n",
      "Epoch 361/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.6105 - accuracy: 0.7706 - val_loss: 0.7202 - val_accuracy: 0.7333 - lr: 8.7816e-04\n",
      "\n",
      "Epoch 362: LearningRateScheduler setting learning rate to 0.0008775238129663223.\n",
      "Epoch 362/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5682 - accuracy: 0.7845 - val_loss: 0.5575 - val_accuracy: 0.7913 - lr: 8.7752e-04\n",
      "\n",
      "Epoch 363: LearningRateScheduler setting learning rate to 0.0008768889271869575.\n",
      "Epoch 363/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5799 - accuracy: 0.7811 - val_loss: 0.6208 - val_accuracy: 0.7656 - lr: 8.7689e-04\n",
      "\n",
      "Epoch 364: LearningRateScheduler setting learning rate to 0.0008762527643057716.\n",
      "Epoch 364/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5927 - accuracy: 0.7779 - val_loss: 0.5496 - val_accuracy: 0.7875 - lr: 8.7625e-04\n",
      "\n",
      "Epoch 365: LearningRateScheduler setting learning rate to 0.0008756153243304217.\n",
      "Epoch 365/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5658 - accuracy: 0.7859 - val_loss: 0.6657 - val_accuracy: 0.7522 - lr: 8.7562e-04\n",
      "\n",
      "Epoch 366: LearningRateScheduler setting learning rate to 0.0008749766072685649.\n",
      "Epoch 366/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5919 - accuracy: 0.7780 - val_loss: 0.6174 - val_accuracy: 0.7673 - lr: 8.7498e-04\n",
      "\n",
      "Epoch 367: LearningRateScheduler setting learning rate to 0.0008743366131278579.\n",
      "Epoch 367/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5723 - accuracy: 0.7845 - val_loss: 0.5978 - val_accuracy: 0.7729 - lr: 8.7434e-04\n",
      "\n",
      "Epoch 368: LearningRateScheduler setting learning rate to 0.0008736953419159575.\n",
      "Epoch 368/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5893 - accuracy: 0.7800 - val_loss: 0.5204 - val_accuracy: 0.8038 - lr: 8.7370e-04\n",
      "\n",
      "Epoch 369: LearningRateScheduler setting learning rate to 0.0008730527936405207.\n",
      "Epoch 369/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5791 - accuracy: 0.7811 - val_loss: 0.5285 - val_accuracy: 0.7987 - lr: 8.7305e-04\n",
      "\n",
      "Epoch 370: LearningRateScheduler setting learning rate to 0.0008724089683092043.\n",
      "Epoch 370/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5679 - accuracy: 0.7850 - val_loss: 0.6252 - val_accuracy: 0.7635 - lr: 8.7241e-04\n",
      "\n",
      "Epoch 371: LearningRateScheduler setting learning rate to 0.0008717638659296647.\n",
      "Epoch 371/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5737 - accuracy: 0.7827 - val_loss: 0.5524 - val_accuracy: 0.7900 - lr: 8.7176e-04\n",
      "\n",
      "Epoch 372: LearningRateScheduler setting learning rate to 0.0008711174865095585.\n",
      "Epoch 372/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5670 - accuracy: 0.7858 - val_loss: 0.5580 - val_accuracy: 0.7864 - lr: 8.7112e-04\n",
      "\n",
      "Epoch 373: LearningRateScheduler setting learning rate to 0.0008704698300565424.\n",
      "Epoch 373/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5675 - accuracy: 0.7863 - val_loss: 0.5392 - val_accuracy: 0.7980 - lr: 8.7047e-04\n",
      "\n",
      "Epoch 374: LearningRateScheduler setting learning rate to 0.0008698209547425435.\n",
      "Epoch 374/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5682 - accuracy: 0.7862 - val_loss: 0.5415 - val_accuracy: 0.7952 - lr: 8.6982e-04\n",
      "\n",
      "Epoch 375: LearningRateScheduler setting learning rate to 0.0008691708024107148.\n",
      "Epoch 375/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5681 - accuracy: 0.7861 - val_loss: 0.5478 - val_accuracy: 0.7916 - lr: 8.6917e-04\n",
      "\n",
      "Epoch 376: LearningRateScheduler setting learning rate to 0.0008685194312327509.\n",
      "Epoch 376/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5730 - accuracy: 0.7823 - val_loss: 0.5619 - val_accuracy: 0.7895 - lr: 8.6852e-04\n",
      "\n",
      "Epoch 377: LearningRateScheduler setting learning rate to 0.0008678667830520376.\n",
      "Epoch 377/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5704 - accuracy: 0.7838 - val_loss: 0.6084 - val_accuracy: 0.7704 - lr: 8.6787e-04\n",
      "\n",
      "Epoch 378: LearningRateScheduler setting learning rate to 0.0008672129160400369.\n",
      "Epoch 378/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5692 - accuracy: 0.7845 - val_loss: 0.5507 - val_accuracy: 0.7928 - lr: 8.6721e-04\n",
      "\n",
      "Epoch 379: LearningRateScheduler setting learning rate to 0.0008665577720403666.\n",
      "Epoch 379/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5878 - accuracy: 0.7785 - val_loss: 0.5191 - val_accuracy: 0.8008 - lr: 8.6656e-04\n",
      "\n",
      "Epoch 380: LearningRateScheduler setting learning rate to 0.0008659014092242561.\n",
      "Epoch 380/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5582 - accuracy: 0.7902 - val_loss: 0.5157 - val_accuracy: 0.8047 - lr: 8.6590e-04\n",
      "\n",
      "Epoch 381: LearningRateScheduler setting learning rate to 0.0008652438275990125.\n",
      "Epoch 381/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5577 - accuracy: 0.7892 - val_loss: 0.5308 - val_accuracy: 0.8044 - lr: 8.6524e-04\n",
      "\n",
      "Epoch 382: LearningRateScheduler setting learning rate to 0.0008645850271719435.\n",
      "Epoch 382/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5709 - accuracy: 0.7841 - val_loss: 0.4912 - val_accuracy: 0.8159 - lr: 8.6459e-04\n",
      "\n",
      "Epoch 383: LearningRateScheduler setting learning rate to 0.0008639250079503557.\n",
      "Epoch 383/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5539 - accuracy: 0.7892 - val_loss: 0.4957 - val_accuracy: 0.8112 - lr: 8.6393e-04\n",
      "\n",
      "Epoch 384: LearningRateScheduler setting learning rate to 0.0008632637699415567.\n",
      "Epoch 384/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5730 - accuracy: 0.7848 - val_loss: 0.5225 - val_accuracy: 0.8018 - lr: 8.6326e-04\n",
      "\n",
      "Epoch 385: LearningRateScheduler setting learning rate to 0.0008626013131528535.\n",
      "Epoch 385/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5806 - accuracy: 0.7817 - val_loss: 0.5255 - val_accuracy: 0.7986 - lr: 8.6260e-04\n",
      "\n",
      "Epoch 386: LearningRateScheduler setting learning rate to 0.0008619376375915534.\n",
      "Epoch 386/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5939 - accuracy: 0.7763 - val_loss: 0.5752 - val_accuracy: 0.7804 - lr: 8.6194e-04\n",
      "\n",
      "Epoch 387: LearningRateScheduler setting learning rate to 0.0008612727432649629.\n",
      "Epoch 387/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5748 - accuracy: 0.7839 - val_loss: 0.5184 - val_accuracy: 0.8012 - lr: 8.6127e-04\n",
      "\n",
      "Epoch 388: LearningRateScheduler setting learning rate to 0.0008606066301803892.\n",
      "Epoch 388/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5642 - accuracy: 0.7857 - val_loss: 0.5208 - val_accuracy: 0.8015 - lr: 8.6061e-04\n",
      "\n",
      "Epoch 389: LearningRateScheduler setting learning rate to 0.0008599392983451393.\n",
      "Epoch 389/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5521 - accuracy: 0.7895 - val_loss: 0.5002 - val_accuracy: 0.8127 - lr: 8.5994e-04\n",
      "\n",
      "Epoch 390: LearningRateScheduler setting learning rate to 0.0008592708059289306.\n",
      "Epoch 390/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5708 - accuracy: 0.7843 - val_loss: 0.6256 - val_accuracy: 0.7635 - lr: 8.5927e-04\n",
      "\n",
      "Epoch 391: LearningRateScheduler setting learning rate to 0.0008586010947764264.\n",
      "Epoch 391/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5829 - accuracy: 0.7815 - val_loss: 0.6551 - val_accuracy: 0.7529 - lr: 8.5860e-04\n",
      "\n",
      "Epoch 392: LearningRateScheduler setting learning rate to 0.0008579301648949338.\n",
      "Epoch 392/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5624 - accuracy: 0.7886 - val_loss: 0.5829 - val_accuracy: 0.7826 - lr: 8.5793e-04\n",
      "\n",
      "Epoch 393: LearningRateScheduler setting learning rate to 0.0008572580744538213.\n",
      "Epoch 393/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5443 - accuracy: 0.7932 - val_loss: 0.5212 - val_accuracy: 0.8003 - lr: 8.5726e-04\n",
      "\n",
      "Epoch 394: LearningRateScheduler setting learning rate to 0.0008565848234600465.\n",
      "Epoch 394/500\n",
      "474/474 [==============================] - 10s 20ms/step - loss: 0.5657 - accuracy: 0.7855 - val_loss: 0.6603 - val_accuracy: 0.7575 - lr: 8.5658e-04\n",
      "\n",
      "Epoch 395: LearningRateScheduler setting learning rate to 0.0008559103537587382.\n",
      "Epoch 395/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5668 - accuracy: 0.7869 - val_loss: 0.6552 - val_accuracy: 0.7560 - lr: 8.5591e-04\n",
      "\n",
      "Epoch 396: LearningRateScheduler setting learning rate to 0.0008552347235189158.\n",
      "Epoch 396/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5552 - accuracy: 0.7904 - val_loss: 0.6865 - val_accuracy: 0.7488 - lr: 8.5523e-04\n",
      "\n",
      "Epoch 397: LearningRateScheduler setting learning rate to 0.0008545579327475371.\n",
      "Epoch 397/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5623 - accuracy: 0.7892 - val_loss: 0.5710 - val_accuracy: 0.7817 - lr: 8.5456e-04\n",
      "\n",
      "Epoch 398: LearningRateScheduler setting learning rate to 0.000853879923290079.\n",
      "Epoch 398/500\n",
      "474/474 [==============================] - 10s 21ms/step - loss: 0.5819 - accuracy: 0.7797 - val_loss: 0.6055 - val_accuracy: 0.7709 - lr: 8.5388e-04\n",
      "\n",
      "Epoch 399: LearningRateScheduler setting learning rate to 0.0008532007533152123.\n",
      "Epoch 399/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5477 - accuracy: 0.7925 - val_loss: 0.7494 - val_accuracy: 0.7285 - lr: 8.5320e-04\n",
      "\n",
      "Epoch 400: LearningRateScheduler setting learning rate to 0.0008525204228298945.\n",
      "Epoch 400/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5546 - accuracy: 0.7919 - val_loss: 0.5125 - val_accuracy: 0.8057 - lr: 8.5252e-04\n",
      "\n",
      "Epoch 401: LearningRateScheduler setting learning rate to 0.0008518389318410835.\n",
      "Epoch 401/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5652 - accuracy: 0.7868 - val_loss: 0.6017 - val_accuracy: 0.7744 - lr: 8.5184e-04\n",
      "\n",
      "Epoch 402: LearningRateScheduler setting learning rate to 0.0008511562803557362.\n",
      "Epoch 402/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5456 - accuracy: 0.7946 - val_loss: 0.6265 - val_accuracy: 0.7674 - lr: 8.5116e-04\n",
      "\n",
      "Epoch 403: LearningRateScheduler setting learning rate to 0.0008504725265417097.\n",
      "Epoch 403/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5819 - accuracy: 0.7808 - val_loss: 0.5234 - val_accuracy: 0.7982 - lr: 8.5047e-04\n",
      "\n",
      "Epoch 404: LearningRateScheduler setting learning rate to 0.0008497876122448292.\n",
      "Epoch 404/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5565 - accuracy: 0.7908 - val_loss: 0.5195 - val_accuracy: 0.8022 - lr: 8.4979e-04\n",
      "\n",
      "Epoch 405: LearningRateScheduler setting learning rate to 0.0008491015374720525.\n",
      "Epoch 405/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5530 - accuracy: 0.7910 - val_loss: 0.6212 - val_accuracy: 0.7659 - lr: 8.4910e-04\n",
      "\n",
      "Epoch 406: LearningRateScheduler setting learning rate to 0.0008484143022303363.\n",
      "Epoch 406/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5598 - accuracy: 0.7897 - val_loss: 0.5822 - val_accuracy: 0.7793 - lr: 8.4841e-04\n",
      "\n",
      "Epoch 407: LearningRateScheduler setting learning rate to 0.0008477259646870725.\n",
      "Epoch 407/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5794 - accuracy: 0.7833 - val_loss: 0.5441 - val_accuracy: 0.7881 - lr: 8.4773e-04\n",
      "\n",
      "Epoch 408: LearningRateScheduler setting learning rate to 0.0008470364666885512.\n",
      "Epoch 408/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5634 - accuracy: 0.7878 - val_loss: 0.5242 - val_accuracy: 0.8028 - lr: 8.4704e-04\n",
      "\n",
      "Epoch 409: LearningRateScheduler setting learning rate to 0.0008463458664019318.\n",
      "Epoch 409/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5654 - accuracy: 0.7882 - val_loss: 0.5878 - val_accuracy: 0.7773 - lr: 8.4635e-04\n",
      "\n",
      "Epoch 410: LearningRateScheduler setting learning rate to 0.0008456541056737364.\n",
      "Epoch 410/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5679 - accuracy: 0.7858 - val_loss: 0.6264 - val_accuracy: 0.7651 - lr: 8.4565e-04\n",
      "\n",
      "Epoch 411: LearningRateScheduler setting learning rate to 0.0008449612426708917.\n",
      "Epoch 411/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5563 - accuracy: 0.7896 - val_loss: 0.5112 - val_accuracy: 0.8046 - lr: 8.4496e-04\n",
      "\n",
      "Epoch 412: LearningRateScheduler setting learning rate to 0.000844267277400006.\n",
      "Epoch 412/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5724 - accuracy: 0.7872 - val_loss: 0.6005 - val_accuracy: 0.7705 - lr: 8.4427e-04\n",
      "\n",
      "Epoch 413: LearningRateScheduler setting learning rate to 0.0008435721517079502.\n",
      "Epoch 413/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5474 - accuracy: 0.7945 - val_loss: 0.4944 - val_accuracy: 0.8105 - lr: 8.4357e-04\n",
      "\n",
      "Epoch 414: LearningRateScheduler setting learning rate to 0.0008428759237613021.\n",
      "Epoch 414/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5331 - accuracy: 0.7988 - val_loss: 0.6001 - val_accuracy: 0.7721 - lr: 8.4288e-04\n",
      "\n",
      "Epoch 415: LearningRateScheduler setting learning rate to 0.0008421785935666697.\n",
      "Epoch 415/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5458 - accuracy: 0.7927 - val_loss: 0.5406 - val_accuracy: 0.7946 - lr: 8.4218e-04\n",
      "\n",
      "Epoch 416: LearningRateScheduler setting learning rate to 0.000841480161130661.\n",
      "Epoch 416/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5781 - accuracy: 0.7832 - val_loss: 0.5271 - val_accuracy: 0.7978 - lr: 8.4148e-04\n",
      "\n",
      "Epoch 417: LearningRateScheduler setting learning rate to 0.0008407806264598844.\n",
      "Epoch 417/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5501 - accuracy: 0.7927 - val_loss: 0.5205 - val_accuracy: 0.8054 - lr: 8.4078e-04\n",
      "\n",
      "Epoch 418: LearningRateScheduler setting learning rate to 0.000840079989560947.\n",
      "Epoch 418/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5281 - accuracy: 0.8006 - val_loss: 0.5326 - val_accuracy: 0.8000 - lr: 8.4008e-04\n",
      "\n",
      "Epoch 419: LearningRateScheduler setting learning rate to 0.0008393782504404572.\n",
      "Epoch 419/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5842 - accuracy: 0.7833 - val_loss: 0.5179 - val_accuracy: 0.8046 - lr: 8.3938e-04\n",
      "\n",
      "Epoch 420: LearningRateScheduler setting learning rate to 0.0008386754672639465.\n",
      "Epoch 420/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5339 - accuracy: 0.7980 - val_loss: 0.6076 - val_accuracy: 0.7734 - lr: 8.3868e-04\n",
      "\n",
      "Epoch 421: LearningRateScheduler setting learning rate to 0.0008379715818788662.\n",
      "Epoch 421/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5734 - accuracy: 0.7848 - val_loss: 0.7237 - val_accuracy: 0.7417 - lr: 8.3797e-04\n",
      "\n",
      "Epoch 422: LearningRateScheduler setting learning rate to 0.0008372665942918241.\n",
      "Epoch 422/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5483 - accuracy: 0.7937 - val_loss: 0.6464 - val_accuracy: 0.7598 - lr: 8.3727e-04\n",
      "\n",
      "Epoch 423: LearningRateScheduler setting learning rate to 0.000836560562668003.\n",
      "Epoch 423/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5568 - accuracy: 0.7916 - val_loss: 0.5198 - val_accuracy: 0.8063 - lr: 8.3656e-04\n",
      "\n",
      "Epoch 424: LearningRateScheduler setting learning rate to 0.0008358534288552031.\n",
      "Epoch 424/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5419 - accuracy: 0.7948 - val_loss: 0.5216 - val_accuracy: 0.8007 - lr: 8.3585e-04\n",
      "\n",
      "Epoch 425: LearningRateScheduler setting learning rate to 0.0008351452510183742.\n",
      "Epoch 425/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5472 - accuracy: 0.7932 - val_loss: 0.6616 - val_accuracy: 0.7599 - lr: 8.3515e-04\n",
      "\n",
      "Epoch 426: LearningRateScheduler setting learning rate to 0.0008344359710055488.\n",
      "Epoch 426/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5626 - accuracy: 0.7875 - val_loss: 0.5539 - val_accuracy: 0.7911 - lr: 8.3444e-04\n",
      "\n",
      "Epoch 427: LearningRateScheduler setting learning rate to 0.0008337256469814447.\n",
      "Epoch 427/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5341 - accuracy: 0.7976 - val_loss: 0.7181 - val_accuracy: 0.7433 - lr: 8.3373e-04\n",
      "\n",
      "Epoch 428: LearningRateScheduler setting learning rate to 0.0008330142789523206.\n",
      "Epoch 428/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5535 - accuracy: 0.7912 - val_loss: 0.4848 - val_accuracy: 0.8143 - lr: 8.3301e-04\n",
      "\n",
      "Epoch 429: LearningRateScheduler setting learning rate to 0.0008323018087665573.\n",
      "Epoch 429/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5422 - accuracy: 0.7952 - val_loss: 0.5294 - val_accuracy: 0.7991 - lr: 8.3230e-04\n",
      "\n",
      "Epoch 430: LearningRateScheduler setting learning rate to 0.0008315882945885237.\n",
      "Epoch 430/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5361 - accuracy: 0.7959 - val_loss: 0.6432 - val_accuracy: 0.7616 - lr: 8.3159e-04\n",
      "\n",
      "Epoch 431: LearningRateScheduler setting learning rate to 0.0008308737364244782.\n",
      "Epoch 431/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5802 - accuracy: 0.7835 - val_loss: 0.5166 - val_accuracy: 0.8040 - lr: 8.3087e-04\n",
      "\n",
      "Epoch 432: LearningRateScheduler setting learning rate to 0.0008301581342806798.\n",
      "Epoch 432/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5317 - accuracy: 0.7998 - val_loss: 0.6069 - val_accuracy: 0.7730 - lr: 8.3016e-04\n",
      "\n",
      "Epoch 433: LearningRateScheduler setting learning rate to 0.0008294414881633863.\n",
      "Epoch 433/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5478 - accuracy: 0.7923 - val_loss: 0.5552 - val_accuracy: 0.7870 - lr: 8.2944e-04\n",
      "\n",
      "Epoch 434: LearningRateScheduler setting learning rate to 0.0008287237980788565.\n",
      "Epoch 434/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5469 - accuracy: 0.7955 - val_loss: 0.5303 - val_accuracy: 0.8004 - lr: 8.2872e-04\n",
      "\n",
      "Epoch 435: LearningRateScheduler setting learning rate to 0.0008280050640333488.\n",
      "Epoch 435/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5349 - accuracy: 0.7989 - val_loss: 0.5828 - val_accuracy: 0.7815 - lr: 8.2801e-04\n",
      "\n",
      "Epoch 436: LearningRateScheduler setting learning rate to 0.0008272853441901858.\n",
      "Epoch 436/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5435 - accuracy: 0.7943 - val_loss: 0.5200 - val_accuracy: 0.8024 - lr: 8.2729e-04\n",
      "\n",
      "Epoch 437: LearningRateScheduler setting learning rate to 0.0008265645803983289.\n",
      "Epoch 437/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5309 - accuracy: 0.7990 - val_loss: 0.6231 - val_accuracy: 0.7661 - lr: 8.2656e-04\n",
      "\n",
      "Epoch 438: LearningRateScheduler setting learning rate to 0.0008258427726640363.\n",
      "Epoch 438/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5334 - accuracy: 0.7993 - val_loss: 0.6878 - val_accuracy: 0.7417 - lr: 8.2584e-04\n",
      "\n",
      "Epoch 439: LearningRateScheduler setting learning rate to 0.000825119979150282.\n",
      "Epoch 439/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5641 - accuracy: 0.7884 - val_loss: 0.4729 - val_accuracy: 0.8217 - lr: 8.2512e-04\n",
      "\n",
      "Epoch 440: LearningRateScheduler setting learning rate to 0.0008243961417063762.\n",
      "Epoch 440/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5223 - accuracy: 0.8033 - val_loss: 0.5158 - val_accuracy: 0.8032 - lr: 8.2440e-04\n",
      "\n",
      "Epoch 441: LearningRateScheduler setting learning rate to 0.0008236713184950596.\n",
      "Epoch 441/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5532 - accuracy: 0.7913 - val_loss: 0.5150 - val_accuracy: 0.8063 - lr: 8.2367e-04\n",
      "\n",
      "Epoch 442: LearningRateScheduler setting learning rate to 0.0008229455095222422.\n",
      "Epoch 442/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5319 - accuracy: 0.7979 - val_loss: 0.5661 - val_accuracy: 0.7865 - lr: 8.2295e-04\n",
      "\n",
      "Epoch 443: LearningRateScheduler setting learning rate to 0.0008222186566375822.\n",
      "Epoch 443/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5775 - accuracy: 0.7841 - val_loss: 0.6053 - val_accuracy: 0.7692 - lr: 8.2222e-04\n",
      "\n",
      "Epoch 444: LearningRateScheduler setting learning rate to 0.0008214908180034724.\n",
      "Epoch 444/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5523 - accuracy: 0.7924 - val_loss: 0.5099 - val_accuracy: 0.8069 - lr: 8.2149e-04\n",
      "\n",
      "Epoch 445: LearningRateScheduler setting learning rate to 0.0008207619936258217.\n",
      "Epoch 445/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5337 - accuracy: 0.7983 - val_loss: 0.5794 - val_accuracy: 0.7801 - lr: 8.2076e-04\n",
      "\n",
      "Epoch 446: LearningRateScheduler setting learning rate to 0.0008200321835105395.\n",
      "Epoch 446/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5248 - accuracy: 0.8014 - val_loss: 0.5048 - val_accuracy: 0.8094 - lr: 8.2003e-04\n",
      "\n",
      "Epoch 447: LearningRateScheduler setting learning rate to 0.0008193013876635351.\n",
      "Epoch 447/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5329 - accuracy: 0.7988 - val_loss: 0.5058 - val_accuracy: 0.8104 - lr: 8.1930e-04\n",
      "\n",
      "Epoch 448: LearningRateScheduler setting learning rate to 0.0008185696060907172.\n",
      "Epoch 448/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5317 - accuracy: 0.7987 - val_loss: 0.5966 - val_accuracy: 0.7779 - lr: 8.1857e-04\n",
      "\n",
      "Epoch 449: LearningRateScheduler setting learning rate to 0.0008178368387979951.\n",
      "Epoch 449/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5427 - accuracy: 0.7959 - val_loss: 0.6958 - val_accuracy: 0.7462 - lr: 8.1784e-04\n",
      "\n",
      "Epoch 450: LearningRateScheduler setting learning rate to 0.0008171030857912778.\n",
      "Epoch 450/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5451 - accuracy: 0.7945 - val_loss: 0.5234 - val_accuracy: 0.8022 - lr: 8.1710e-04\n",
      "\n",
      "Epoch 451: LearningRateScheduler setting learning rate to 0.0008163683470764746.\n",
      "Epoch 451/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5327 - accuracy: 0.7985 - val_loss: 0.7391 - val_accuracy: 0.7343 - lr: 8.1637e-04\n",
      "\n",
      "Epoch 452: LearningRateScheduler setting learning rate to 0.0008156326226594938.\n",
      "Epoch 452/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5464 - accuracy: 0.7924 - val_loss: 0.6852 - val_accuracy: 0.7469 - lr: 8.1563e-04\n",
      "\n",
      "Epoch 453: LearningRateScheduler setting learning rate to 0.0008148959707013333.\n",
      "Epoch 453/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5342 - accuracy: 0.7980 - val_loss: 0.4984 - val_accuracy: 0.8120 - lr: 8.1490e-04\n",
      "\n",
      "Epoch 454: LearningRateScheduler setting learning rate to 0.0008141583330525808.\n",
      "Epoch 454/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5213 - accuracy: 0.8042 - val_loss: 0.5241 - val_accuracy: 0.8016 - lr: 8.1416e-04\n",
      "\n",
      "Epoch 455: LearningRateScheduler setting learning rate to 0.0008134197678740015.\n",
      "Epoch 455/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5203 - accuracy: 0.8040 - val_loss: 0.5664 - val_accuracy: 0.7880 - lr: 8.1342e-04\n",
      "\n",
      "Epoch 456: LearningRateScheduler setting learning rate to 0.0008126802170164151.\n",
      "Epoch 456/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5272 - accuracy: 0.8010 - val_loss: 0.5261 - val_accuracy: 0.8026 - lr: 8.1268e-04\n",
      "\n",
      "Epoch 457: LearningRateScheduler setting learning rate to 0.0008119397386403544.\n",
      "Epoch 457/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5542 - accuracy: 0.7920 - val_loss: 0.5966 - val_accuracy: 0.7742 - lr: 8.1194e-04\n",
      "\n",
      "Epoch 458: LearningRateScheduler setting learning rate to 0.0008111982745968717.\n",
      "Epoch 458/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5230 - accuracy: 0.8022 - val_loss: 0.4905 - val_accuracy: 0.8146 - lr: 8.1120e-04\n",
      "\n",
      "Epoch 459: LearningRateScheduler setting learning rate to 0.0008104558830462673.\n",
      "Epoch 459/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5307 - accuracy: 0.7996 - val_loss: 0.6033 - val_accuracy: 0.7685 - lr: 8.1046e-04\n",
      "\n",
      "Epoch 460: LearningRateScheduler setting learning rate to 0.0008097125639941006.\n",
      "Epoch 460/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5406 - accuracy: 0.7964 - val_loss: 0.5934 - val_accuracy: 0.7758 - lr: 8.0971e-04\n",
      "\n",
      "Epoch 461: LearningRateScheduler setting learning rate to 0.0008089683174459319.\n",
      "Epoch 461/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5294 - accuracy: 0.7988 - val_loss: 0.5333 - val_accuracy: 0.7953 - lr: 8.0897e-04\n",
      "\n",
      "Epoch 462: LearningRateScheduler setting learning rate to 0.000808223143407321.\n",
      "Epoch 462/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5428 - accuracy: 0.7974 - val_loss: 0.5165 - val_accuracy: 0.8027 - lr: 8.0822e-04\n",
      "\n",
      "Epoch 463: LearningRateScheduler setting learning rate to 0.0008074770418838278.\n",
      "Epoch 463/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5281 - accuracy: 0.8003 - val_loss: 0.4866 - val_accuracy: 0.8168 - lr: 8.0748e-04\n",
      "\n",
      "Epoch 464: LearningRateScheduler setting learning rate to 0.0008067300128810118.\n",
      "Epoch 464/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5322 - accuracy: 0.7987 - val_loss: 0.4972 - val_accuracy: 0.8114 - lr: 8.0673e-04\n",
      "\n",
      "Epoch 465: LearningRateScheduler setting learning rate to 0.0008059820564044328.\n",
      "Epoch 465/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5197 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.8100 - lr: 8.0598e-04\n",
      "\n",
      "Epoch 466: LearningRateScheduler setting learning rate to 0.0008052331724596505.\n",
      "Epoch 466/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5321 - accuracy: 0.7985 - val_loss: 0.4691 - val_accuracy: 0.8246 - lr: 8.0523e-04\n",
      "\n",
      "Epoch 467: LearningRateScheduler setting learning rate to 0.0008044834192056867.\n",
      "Epoch 467/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5273 - accuracy: 0.8002 - val_loss: 0.4869 - val_accuracy: 0.8137 - lr: 8.0448e-04\n",
      "\n",
      "Epoch 468: LearningRateScheduler setting learning rate to 0.0008037327384944062.\n",
      "Epoch 468/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5165 - accuracy: 0.8048 - val_loss: 0.4995 - val_accuracy: 0.8131 - lr: 8.0373e-04\n",
      "\n",
      "Epoch 469: LearningRateScheduler setting learning rate to 0.0008029811303313688.\n",
      "Epoch 469/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5294 - accuracy: 0.8014 - val_loss: 0.5617 - val_accuracy: 0.7898 - lr: 8.0298e-04\n",
      "\n",
      "Epoch 470: LearningRateScheduler setting learning rate to 0.0008022286528752472.\n",
      "Epoch 470/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5251 - accuracy: 0.8034 - val_loss: 0.4814 - val_accuracy: 0.8172 - lr: 8.0223e-04\n",
      "\n",
      "Epoch 471: LearningRateScheduler setting learning rate to 0.0008014752479782555.\n",
      "Epoch 471/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5136 - accuracy: 0.8063 - val_loss: 0.6838 - val_accuracy: 0.7499 - lr: 8.0148e-04\n",
      "\n",
      "Epoch 472: LearningRateScheduler setting learning rate to 0.0008007209737988334.\n",
      "Epoch 472/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5208 - accuracy: 0.8036 - val_loss: 0.4666 - val_accuracy: 0.8228 - lr: 8.0072e-04\n",
      "\n",
      "Epoch 473: LearningRateScheduler setting learning rate to 0.0007999658303421922.\n",
      "Epoch 473/500\n",
      "474/474 [==============================] - 10s 22ms/step - loss: 0.5387 - accuracy: 0.7966 - val_loss: 0.4749 - val_accuracy: 0.8244 - lr: 7.9997e-04\n",
      "\n",
      "Epoch 474: LearningRateScheduler setting learning rate to 0.000799209759460894.\n",
      "Epoch 474/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5335 - accuracy: 0.7990 - val_loss: 0.5077 - val_accuracy: 0.8027 - lr: 7.9921e-04\n",
      "\n",
      "Epoch 475: LearningRateScheduler setting learning rate to 0.0007984528193130301.\n",
      "Epoch 475/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5189 - accuracy: 0.8035 - val_loss: 0.5436 - val_accuracy: 0.8010 - lr: 7.9845e-04\n",
      "\n",
      "Epoch 476: LearningRateScheduler setting learning rate to 0.0007976950099038116.\n",
      "Epoch 476/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5213 - accuracy: 0.8045 - val_loss: 0.5098 - val_accuracy: 0.8073 - lr: 7.9770e-04\n",
      "\n",
      "Epoch 477: LearningRateScheduler setting learning rate to 0.0007969363312384487.\n",
      "Epoch 477/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5133 - accuracy: 0.8073 - val_loss: 0.4666 - val_accuracy: 0.8265 - lr: 7.9694e-04\n",
      "\n",
      "Epoch 478: LearningRateScheduler setting learning rate to 0.0007961767833221524.\n",
      "Epoch 478/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5209 - accuracy: 0.8036 - val_loss: 0.5563 - val_accuracy: 0.7895 - lr: 7.9618e-04\n",
      "\n",
      "Epoch 479: LearningRateScheduler setting learning rate to 0.0007954163661601327.\n",
      "Epoch 479/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.4931 - accuracy: 0.8141 - val_loss: 0.6014 - val_accuracy: 0.7747 - lr: 7.9542e-04\n",
      "\n",
      "Epoch 480: LearningRateScheduler setting learning rate to 0.0007946550797576004.\n",
      "Epoch 480/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5113 - accuracy: 0.8057 - val_loss: 0.5026 - val_accuracy: 0.8081 - lr: 7.9466e-04\n",
      "\n",
      "Epoch 481: LearningRateScheduler setting learning rate to 0.000793892924119766.\n",
      "Epoch 481/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5337 - accuracy: 0.7992 - val_loss: 0.4816 - val_accuracy: 0.8184 - lr: 7.9389e-04\n",
      "\n",
      "Epoch 482: LearningRateScheduler setting learning rate to 0.0007931299574035588.\n",
      "Epoch 482/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5116 - accuracy: 0.8059 - val_loss: 0.4768 - val_accuracy: 0.8225 - lr: 7.9313e-04\n",
      "\n",
      "Epoch 483: LearningRateScheduler setting learning rate to 0.0007923661214622377.\n",
      "Epoch 483/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5153 - accuracy: 0.8067 - val_loss: 0.5028 - val_accuracy: 0.8091 - lr: 7.9237e-04\n",
      "\n",
      "Epoch 484: LearningRateScheduler setting learning rate to 0.000791601416301013.\n",
      "Epoch 484/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5259 - accuracy: 0.8015 - val_loss: 0.5520 - val_accuracy: 0.7918 - lr: 7.9160e-04\n",
      "\n",
      "Epoch 485: LearningRateScheduler setting learning rate to 0.0007908359000764654.\n",
      "Epoch 485/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5495 - accuracy: 0.7946 - val_loss: 0.4833 - val_accuracy: 0.8155 - lr: 7.9084e-04\n",
      "\n",
      "Epoch 486: LearningRateScheduler setting learning rate to 0.0007900695146422028.\n",
      "Epoch 486/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5046 - accuracy: 0.8094 - val_loss: 0.5220 - val_accuracy: 0.8044 - lr: 7.9007e-04\n",
      "\n",
      "Epoch 487: LearningRateScheduler setting learning rate to 0.0007893023181545728.\n",
      "Epoch 487/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.4874 - accuracy: 0.8162 - val_loss: 0.4687 - val_accuracy: 0.8245 - lr: 7.8930e-04\n",
      "\n",
      "Epoch 488: LearningRateScheduler setting learning rate to 0.000788534310618437.\n",
      "Epoch 488/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5423 - accuracy: 0.7968 - val_loss: 0.4926 - val_accuracy: 0.8166 - lr: 7.8853e-04\n",
      "\n",
      "Epoch 489: LearningRateScheduler setting learning rate to 0.0007877654338877517.\n",
      "Epoch 489/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5068 - accuracy: 0.8093 - val_loss: 0.5435 - val_accuracy: 0.7936 - lr: 7.8777e-04\n",
      "\n",
      "Epoch 490: LearningRateScheduler setting learning rate to 0.0007869957461185164.\n",
      "Epoch 490/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5552 - accuracy: 0.7933 - val_loss: 0.6274 - val_accuracy: 0.7720 - lr: 7.8700e-04\n",
      "\n",
      "Epoch 491: LearningRateScheduler setting learning rate to 0.0007862252473155921.\n",
      "Epoch 491/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.4921 - accuracy: 0.8143 - val_loss: 0.5061 - val_accuracy: 0.8092 - lr: 7.8623e-04\n",
      "\n",
      "Epoch 492: LearningRateScheduler setting learning rate to 0.0007854539374838408.\n",
      "Epoch 492/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5076 - accuracy: 0.8071 - val_loss: 0.4759 - val_accuracy: 0.8181 - lr: 7.8545e-04\n",
      "\n",
      "Epoch 493: LearningRateScheduler setting learning rate to 0.0007846818166281234.\n",
      "Epoch 493/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5009 - accuracy: 0.8111 - val_loss: 0.5034 - val_accuracy: 0.8063 - lr: 7.8468e-04\n",
      "\n",
      "Epoch 494: LearningRateScheduler setting learning rate to 0.0007839088847533017.\n",
      "Epoch 494/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5157 - accuracy: 0.8055 - val_loss: 0.5302 - val_accuracy: 0.8005 - lr: 7.8391e-04\n",
      "\n",
      "Epoch 495: LearningRateScheduler setting learning rate to 0.0007831351418642366.\n",
      "Epoch 495/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5076 - accuracy: 0.8060 - val_loss: 0.4673 - val_accuracy: 0.8211 - lr: 7.8314e-04\n",
      "\n",
      "Epoch 496: LearningRateScheduler setting learning rate to 0.0007823605879657896.\n",
      "Epoch 496/500\n",
      "474/474 [==============================] - 11s 22ms/step - loss: 0.5206 - accuracy: 0.8031 - val_loss: 0.5047 - val_accuracy: 0.8070 - lr: 7.8236e-04\n",
      "\n",
      "Epoch 497: LearningRateScheduler setting learning rate to 0.000781585281212798.\n",
      "Epoch 497/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5095 - accuracy: 0.8082 - val_loss: 0.5008 - val_accuracy: 0.8094 - lr: 7.8159e-04\n",
      "\n",
      "Epoch 498: LearningRateScheduler setting learning rate to 0.0007808091634599147.\n",
      "Epoch 498/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5326 - accuracy: 0.8015 - val_loss: 0.5243 - val_accuracy: 0.8059 - lr: 7.8081e-04\n",
      "\n",
      "Epoch 499: LearningRateScheduler setting learning rate to 0.0007800322347120004.\n",
      "Epoch 499/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5511 - accuracy: 0.7935 - val_loss: 0.4863 - val_accuracy: 0.8166 - lr: 7.8003e-04\n",
      "\n",
      "Epoch 500: LearningRateScheduler setting learning rate to 0.0007792545531235442.\n",
      "Epoch 500/500\n",
      "474/474 [==============================] - 11s 23ms/step - loss: 0.5016 - accuracy: 0.8117 - val_loss: 0.4927 - val_accuracy: 0.8162 - lr: 7.7925e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V14. Batch Size 128, initial learning rate 1e-3.\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "epochs = 500\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "learning_rate = callbacks.LearningRateScheduler(lr_time_based_decay, verbose=1)\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\"classifier_14_128.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(training_set, validation_data=test_set, epochs=500, callbacks = [learning_rate, checkpoint_cb])\n",
    "\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 14:26:43.694878: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-30 14:26:43.695268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.6701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 14:26:45.884154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 3s 35ms/step - loss: 0.9270 - accuracy: 0.6701 - val_loss: 1.3864 - val_accuracy: 0.1442 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009999967141750706.\n",
      "Epoch 2/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.7006 - accuracy: 0.7524 - val_loss: 1.4514 - val_accuracy: 0.2957 - lr: 1.0000e-03\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000999990004853086.\n",
      "Epoch 3/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.6095 - accuracy: 0.7704 - val_loss: 1.0928 - val_accuracy: 0.5185 - lr: 9.9999e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0009999800359794142.\n",
      "Epoch 4/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.5646 - accuracy: 0.7824 - val_loss: 1.2163 - val_accuracy: 0.5613 - lr: 9.9998e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009999666911728814.\n",
      "Epoch 5/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4984 - accuracy: 0.7952 - val_loss: 0.4753 - val_accuracy: 0.8016 - lr: 9.9997e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0009999499704672458.\n",
      "Epoch 6/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4582 - accuracy: 0.8107 - val_loss: 0.4599 - val_accuracy: 0.8150 - lr: 9.9995e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0009999299903092596.\n",
      "Epoch 7/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.4504 - accuracy: 0.8109 - val_loss: 0.4382 - val_accuracy: 0.8165 - lr: 9.9993e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0009999066343189108.\n",
      "Epoch 8/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4377 - accuracy: 0.8186 - val_loss: 0.4149 - val_accuracy: 0.8264 - lr: 9.9991e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0009998800189421743.\n",
      "Epoch 9/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.4222 - accuracy: 0.8240 - val_loss: 0.4000 - val_accuracy: 0.8360 - lr: 9.9988e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009998500277998137.\n",
      "Epoch 10/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4172 - accuracy: 0.8264 - val_loss: 0.3764 - val_accuracy: 0.8440 - lr: 9.9985e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009998166609255855.\n",
      "Epoch 11/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4114 - accuracy: 0.8274 - val_loss: 0.3840 - val_accuracy: 0.8413 - lr: 9.9982e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000999780034764299.\n",
      "Epoch 12/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.4096 - accuracy: 0.8273 - val_loss: 0.3685 - val_accuracy: 0.8483 - lr: 9.9978e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009997400329378808.\n",
      "Epoch 13/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3999 - accuracy: 0.8357 - val_loss: 0.3648 - val_accuracy: 0.8503 - lr: 9.9974e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0009996966554800858.\n",
      "Epoch 14/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3984 - accuracy: 0.8338 - val_loss: 0.3733 - val_accuracy: 0.8435 - lr: 9.9970e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.000999650018834558.\n",
      "Epoch 15/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3863 - accuracy: 0.8396 - val_loss: 0.3611 - val_accuracy: 0.8478 - lr: 9.9965e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0009996000066243864.\n",
      "Epoch 16/300\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.3950 - accuracy: 0.8337 - val_loss: 0.4022 - val_accuracy: 0.8325 - lr: 9.9960e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0009995467352924385.\n",
      "Epoch 17/300\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.3916 - accuracy: 0.8374 - val_loss: 0.3513 - val_accuracy: 0.8511 - lr: 9.9955e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0009994900884625778.\n",
      "Epoch 18/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3811 - accuracy: 0.8421 - val_loss: 0.3542 - val_accuracy: 0.8532 - lr: 9.9949e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0009994300661685575.\n",
      "Epoch 19/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3772 - accuracy: 0.8431 - val_loss: 0.3662 - val_accuracy: 0.8449 - lr: 9.9943e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0009993667848520794.\n",
      "Epoch 20/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3757 - accuracy: 0.8425 - val_loss: 0.3773 - val_accuracy: 0.8397 - lr: 9.9937e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0009993001281381703.\n",
      "Epoch 21/300\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.3798 - accuracy: 0.8429 - val_loss: 0.3438 - val_accuracy: 0.8554 - lr: 9.9930e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000999230212467755.\n",
      "Epoch 22/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3776 - accuracy: 0.8424 - val_loss: 0.3381 - val_accuracy: 0.8609 - lr: 9.9923e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0009991569214666356.\n",
      "Epoch 23/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3748 - accuracy: 0.8438 - val_loss: 0.3554 - val_accuracy: 0.8528 - lr: 9.9916e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0009990803715749599.\n",
      "Epoch 24/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3705 - accuracy: 0.8476 - val_loss: 0.3465 - val_accuracy: 0.8579 - lr: 9.9908e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0009990004464193048.\n",
      "Epoch 25/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3654 - accuracy: 0.8479 - val_loss: 0.3431 - val_accuracy: 0.8506 - lr: 9.9900e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0009989171460334206.\n",
      "Epoch 26/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3709 - accuracy: 0.8455 - val_loss: 0.3404 - val_accuracy: 0.8599 - lr: 9.9892e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0009988305868562897.\n",
      "Epoch 27/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3743 - accuracy: 0.8432 - val_loss: 0.3448 - val_accuracy: 0.8538 - lr: 9.9883e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0009987406525156517.\n",
      "Epoch 28/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3679 - accuracy: 0.8444 - val_loss: 0.3402 - val_accuracy: 0.8606 - lr: 9.9874e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0009986474594497123.\n",
      "Epoch 29/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3615 - accuracy: 0.8499 - val_loss: 0.3373 - val_accuracy: 0.8607 - lr: 9.9865e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0009985508912869864.\n",
      "Epoch 30/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3675 - accuracy: 0.8464 - val_loss: 0.3420 - val_accuracy: 0.8559 - lr: 9.9855e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000998451064464903.\n",
      "Epoch 31/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3659 - accuracy: 0.8480 - val_loss: 0.3395 - val_accuracy: 0.8613 - lr: 9.9845e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009983478626127522.\n",
      "Epoch 32/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3611 - accuracy: 0.8503 - val_loss: 0.3299 - val_accuracy: 0.8609 - lr: 9.9835e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0009982414021671856.\n",
      "Epoch 33/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3610 - accuracy: 0.8511 - val_loss: 0.3425 - val_accuracy: 0.8565 - lr: 9.9824e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0009981315667582683.\n",
      "Epoch 34/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3561 - accuracy: 0.8518 - val_loss: 0.3410 - val_accuracy: 0.8507 - lr: 9.9813e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0009980184728218759.\n",
      "Epoch 35/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3554 - accuracy: 0.8524 - val_loss: 0.3280 - val_accuracy: 0.8609 - lr: 9.9802e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0009979020039888478.\n",
      "Epoch 36/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3561 - accuracy: 0.8526 - val_loss: 0.3502 - val_accuracy: 0.8565 - lr: 9.9790e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0009977822766942832.\n",
      "Epoch 37/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3566 - accuracy: 0.8524 - val_loss: 0.3327 - val_accuracy: 0.8669 - lr: 9.9778e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0009976591745697963.\n",
      "Epoch 38/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3546 - accuracy: 0.8537 - val_loss: 0.3347 - val_accuracy: 0.8603 - lr: 9.9766e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0009975328140497091.\n",
      "Epoch 39/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3564 - accuracy: 0.8513 - val_loss: 0.3314 - val_accuracy: 0.8635 - lr: 9.9753e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0009974031951666014.\n",
      "Epoch 40/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3534 - accuracy: 0.8526 - val_loss: 0.3269 - val_accuracy: 0.8673 - lr: 9.9740e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009972702015532508.\n",
      "Epoch 41/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3583 - accuracy: 0.8499 - val_loss: 0.3258 - val_accuracy: 0.8637 - lr: 9.9727e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0009971339496428137.\n",
      "Epoch 42/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3505 - accuracy: 0.8571 - val_loss: 0.3097 - val_accuracy: 0.8720 - lr: 9.9713e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009969943230688425.\n",
      "Epoch 43/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3512 - accuracy: 0.8544 - val_loss: 0.3392 - val_accuracy: 0.8569 - lr: 9.9699e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009968514382637172.\n",
      "Epoch 44/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3569 - accuracy: 0.8532 - val_loss: 0.3416 - val_accuracy: 0.8602 - lr: 9.9685e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.000996705295260015.\n",
      "Epoch 45/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3531 - accuracy: 0.8556 - val_loss: 0.3473 - val_accuracy: 0.8593 - lr: 9.9671e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009965557776924513.\n",
      "Epoch 46/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3563 - accuracy: 0.8535 - val_loss: 0.3265 - val_accuracy: 0.8672 - lr: 9.9656e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0009964030019922409.\n",
      "Epoch 47/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3483 - accuracy: 0.8567 - val_loss: 0.3188 - val_accuracy: 0.8685 - lr: 9.9640e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0009962469681919594.\n",
      "Epoch 48/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3504 - accuracy: 0.8551 - val_loss: 0.3345 - val_accuracy: 0.8638 - lr: 9.9625e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0009960875599274845.\n",
      "Epoch 49/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3536 - accuracy: 0.8530 - val_loss: 0.3304 - val_accuracy: 0.8653 - lr: 9.9609e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009959248936288656.\n",
      "Epoch 50/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3478 - accuracy: 0.8548 - val_loss: 0.3376 - val_accuracy: 0.8553 - lr: 9.9592e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.000995758969328678.\n",
      "Epoch 51/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3483 - accuracy: 0.8546 - val_loss: 0.3354 - val_accuracy: 0.8609 - lr: 9.9576e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0009955896706639613.\n",
      "Epoch 52/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3495 - accuracy: 0.8547 - val_loss: 0.3211 - val_accuracy: 0.8660 - lr: 9.9559e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0009954171140636.\n",
      "Epoch 53/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3413 - accuracy: 0.8569 - val_loss: 0.3316 - val_accuracy: 0.8637 - lr: 9.9542e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.000995241299560168.\n",
      "Epoch 54/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3430 - accuracy: 0.8595 - val_loss: 0.3213 - val_accuracy: 0.8665 - lr: 9.9524e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.000995062227186238.\n",
      "Epoch 55/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3481 - accuracy: 0.8556 - val_loss: 0.3274 - val_accuracy: 0.8593 - lr: 9.9506e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009948797805804002.\n",
      "Epoch 56/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3459 - accuracy: 0.8563 - val_loss: 0.3138 - val_accuracy: 0.8752 - lr: 9.9488e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009946940761699856.\n",
      "Epoch 57/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3424 - accuracy: 0.8609 - val_loss: 0.3227 - val_accuracy: 0.8688 - lr: 9.9469e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009945051139875658.\n",
      "Epoch 58/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3465 - accuracy: 0.8563 - val_loss: 0.3187 - val_accuracy: 0.8694 - lr: 9.9451e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.000994312894065712.\n",
      "Epoch 59/300\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.3427 - accuracy: 0.8580 - val_loss: 0.3071 - val_accuracy: 0.8756 - lr: 9.9431e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.000994117416436996.\n",
      "Epoch 60/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3424 - accuracy: 0.8601 - val_loss: 0.3232 - val_accuracy: 0.8626 - lr: 9.9412e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0009939186811339876.\n",
      "Epoch 61/300\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.3451 - accuracy: 0.8596 - val_loss: 0.3148 - val_accuracy: 0.8701 - lr: 9.9392e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0009937165717976018.\n",
      "Epoch 62/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3524 - accuracy: 0.8549 - val_loss: 0.3384 - val_accuracy: 0.8594 - lr: 9.9372e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0009935112048528396.\n",
      "Epoch 63/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3441 - accuracy: 0.8584 - val_loss: 0.3208 - val_accuracy: 0.8684 - lr: 9.9351e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.00099330258033227.\n",
      "Epoch 64/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3447 - accuracy: 0.8600 - val_loss: 0.3199 - val_accuracy: 0.8717 - lr: 9.9330e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.000993090698268462.\n",
      "Epoch 65/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3417 - accuracy: 0.8592 - val_loss: 0.3000 - val_accuracy: 0.8789 - lr: 9.9309e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0009928755586939837.\n",
      "Epoch 66/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3398 - accuracy: 0.8591 - val_loss: 0.3181 - val_accuracy: 0.8717 - lr: 9.9288e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0009926571616414035.\n",
      "Epoch 67/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3358 - accuracy: 0.8620 - val_loss: 0.2977 - val_accuracy: 0.8787 - lr: 9.9266e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0009924355071432888.\n",
      "Epoch 68/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3417 - accuracy: 0.8576 - val_loss: 0.3018 - val_accuracy: 0.8791 - lr: 9.9244e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0009922105952322063.\n",
      "Epoch 69/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3440 - accuracy: 0.8585 - val_loss: 0.3125 - val_accuracy: 0.8729 - lr: 9.9221e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.000991982425940723.\n",
      "Epoch 70/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3339 - accuracy: 0.8625 - val_loss: 0.3141 - val_accuracy: 0.8693 - lr: 9.9198e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0009917509993014049.\n",
      "Epoch 71/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3355 - accuracy: 0.8615 - val_loss: 0.2943 - val_accuracy: 0.8803 - lr: 9.9175e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0009915163153468177.\n",
      "Epoch 72/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3349 - accuracy: 0.8627 - val_loss: 0.3131 - val_accuracy: 0.8736 - lr: 9.9152e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0009912783741095272.\n",
      "Epoch 73/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3333 - accuracy: 0.8619 - val_loss: 0.3163 - val_accuracy: 0.8692 - lr: 9.9128e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0009910371756220978.\n",
      "Epoch 74/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3376 - accuracy: 0.8615 - val_loss: 0.3213 - val_accuracy: 0.8682 - lr: 9.9104e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0009907928363037074.\n",
      "Epoch 75/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3400 - accuracy: 0.8591 - val_loss: 0.3176 - val_accuracy: 0.8716 - lr: 9.9079e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.000990545239799531.\n",
      "Epoch 76/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3340 - accuracy: 0.8619 - val_loss: 0.3100 - val_accuracy: 0.8704 - lr: 9.9055e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0009902943861421322.\n",
      "Epoch 77/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3428 - accuracy: 0.8579 - val_loss: 0.3052 - val_accuracy: 0.8757 - lr: 9.9029e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0009900402753640746.\n",
      "Epoch 78/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3378 - accuracy: 0.8609 - val_loss: 0.3226 - val_accuracy: 0.8645 - lr: 9.9004e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0009897829074979204.\n",
      "Epoch 79/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3314 - accuracy: 0.8625 - val_loss: 0.3069 - val_accuracy: 0.8759 - lr: 9.8978e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.000989522282576232.\n",
      "Epoch 80/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3333 - accuracy: 0.8633 - val_loss: 0.3129 - val_accuracy: 0.8684 - lr: 9.8952e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0009892585170158574.\n",
      "Epoch 81/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3348 - accuracy: 0.8601 - val_loss: 0.3155 - val_accuracy: 0.8701 - lr: 9.8926e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0009889914944642966.\n",
      "Epoch 82/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.3326 - accuracy: 0.8619 - val_loss: 0.3087 - val_accuracy: 0.8710 - lr: 9.8899e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.00098872121495411.\n",
      "Epoch 83/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3359 - accuracy: 0.8626 - val_loss: 0.3081 - val_accuracy: 0.8740 - lr: 9.8872e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0009884477949009813.\n",
      "Epoch 84/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3303 - accuracy: 0.8650 - val_loss: 0.3099 - val_accuracy: 0.8751 - lr: 9.8845e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.000988171117953572.\n",
      "Epoch 85/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3293 - accuracy: 0.8654 - val_loss: 0.2995 - val_accuracy: 0.8740 - lr: 9.8817e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0009878911841444422.\n",
      "Epoch 86/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3324 - accuracy: 0.8641 - val_loss: 0.3025 - val_accuracy: 0.8784 - lr: 9.8789e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0009876081098881097.\n",
      "Epoch 87/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3306 - accuracy: 0.8641 - val_loss: 0.2993 - val_accuracy: 0.8767 - lr: 9.8761e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0009873217788343995.\n",
      "Epoch 88/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3361 - accuracy: 0.8622 - val_loss: 0.2956 - val_accuracy: 0.8781 - lr: 9.8732e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0009870323073970526.\n",
      "Epoch 89/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3304 - accuracy: 0.8618 - val_loss: 0.3035 - val_accuracy: 0.8767 - lr: 9.8703e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0009867395792266683.\n",
      "Epoch 90/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3306 - accuracy: 0.8645 - val_loss: 0.2963 - val_accuracy: 0.8821 - lr: 9.8674e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.000986443594355804.\n",
      "Epoch 91/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3241 - accuracy: 0.8663 - val_loss: 0.3073 - val_accuracy: 0.8688 - lr: 9.8644e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.000986144469197037.\n",
      "Epoch 92/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3320 - accuracy: 0.8654 - val_loss: 0.2972 - val_accuracy: 0.8797 - lr: 9.8614e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.000985842087402128.\n",
      "Epoch 93/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3310 - accuracy: 0.8620 - val_loss: 0.3035 - val_accuracy: 0.8759 - lr: 9.8584e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.000985536565382878.\n",
      "Epoch 94/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3230 - accuracy: 0.8676 - val_loss: 0.3031 - val_accuracy: 0.8752 - lr: 9.8554e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0009852279031706795.\n",
      "Epoch 95/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3264 - accuracy: 0.8655 - val_loss: 0.2954 - val_accuracy: 0.8797 - lr: 9.8523e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0009849159844184552.\n",
      "Epoch 96/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3218 - accuracy: 0.8691 - val_loss: 0.2934 - val_accuracy: 0.8804 - lr: 9.8492e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0009846009255368416.\n",
      "Epoch 97/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3336 - val_accuracy: 0.8643 - lr: 9.8460e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0009842827265572297.\n",
      "Epoch 98/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3338 - accuracy: 0.8625 - val_loss: 0.2984 - val_accuracy: 0.8755 - lr: 9.8428e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0009839612711337047.\n",
      "Epoch 99/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3303 - accuracy: 0.8628 - val_loss: 0.3001 - val_accuracy: 0.8748 - lr: 9.8396e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.000983636675675738.\n",
      "Epoch 100/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3282 - accuracy: 0.8649 - val_loss: 0.3073 - val_accuracy: 0.8726 - lr: 9.8364e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0009833089402147192.\n",
      "Epoch 101/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3274 - accuracy: 0.8649 - val_loss: 0.3000 - val_accuracy: 0.8721 - lr: 9.8331e-04\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.000982977948405896.\n",
      "Epoch 102/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3275 - accuracy: 0.8657 - val_loss: 0.2928 - val_accuracy: 0.8785 - lr: 9.8298e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0009826438166575752.\n",
      "Epoch 103/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3319 - accuracy: 0.8628 - val_loss: 0.2923 - val_accuracy: 0.8841 - lr: 9.8264e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.000982306545001145.\n",
      "Epoch 104/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3269 - accuracy: 0.8647 - val_loss: 0.3080 - val_accuracy: 0.8742 - lr: 9.8231e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0009819661334679937.\n",
      "Epoch 105/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3328 - accuracy: 0.8618 - val_loss: 0.3081 - val_accuracy: 0.8729 - lr: 9.8197e-04\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.0009816225820895093.\n",
      "Epoch 106/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3344 - accuracy: 0.8626 - val_loss: 0.3026 - val_accuracy: 0.8764 - lr: 9.8162e-04\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.0009812758908970792.\n",
      "Epoch 107/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3292 - accuracy: 0.8636 - val_loss: 0.2902 - val_accuracy: 0.8799 - lr: 9.8128e-04\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.00098092605992209.\n",
      "Epoch 108/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3242 - accuracy: 0.8672 - val_loss: 0.3072 - val_accuracy: 0.8737 - lr: 9.8093e-04\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.0009805730891959286.\n",
      "Epoch 109/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3257 - accuracy: 0.8649 - val_loss: 0.3006 - val_accuracy: 0.8777 - lr: 9.8057e-04\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.0009802169787499807.\n",
      "Epoch 110/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3306 - accuracy: 0.8640 - val_loss: 0.3016 - val_accuracy: 0.8775 - lr: 9.8022e-04\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.000979857728615632.\n",
      "Epoch 111/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3269 - accuracy: 0.8652 - val_loss: 0.2912 - val_accuracy: 0.8820 - lr: 9.7986e-04\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.0009794953388242683.\n",
      "Epoch 112/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3234 - accuracy: 0.8642 - val_loss: 0.2866 - val_accuracy: 0.8840 - lr: 9.7950e-04\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.0009791298094072739.\n",
      "Epoch 113/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3251 - accuracy: 0.8666 - val_loss: 0.3004 - val_accuracy: 0.8768 - lr: 9.7913e-04\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.0009787611403960334.\n",
      "Epoch 114/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3238 - accuracy: 0.8677 - val_loss: 0.2948 - val_accuracy: 0.8829 - lr: 9.7876e-04\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.0009783893318219311.\n",
      "Epoch 115/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3325 - accuracy: 0.8603 - val_loss: 0.2933 - val_accuracy: 0.8793 - lr: 9.7839e-04\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.0009780143837163503.\n",
      "Epoch 116/300\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3202 - accuracy: 0.8687 - val_loss: 0.3088 - val_accuracy: 0.8729 - lr: 9.7801e-04\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.0009776364124809995.\n",
      "Epoch 117/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3246 - accuracy: 0.8674 - val_loss: 0.2871 - val_accuracy: 0.8825 - lr: 9.7764e-04\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.000977255301776161.\n",
      "Epoch 118/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3263 - accuracy: 0.8651 - val_loss: 0.3141 - val_accuracy: 0.8717 - lr: 9.7726e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.0009768710516332164.\n",
      "Epoch 119/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3172 - accuracy: 0.8693 - val_loss: 0.2891 - val_accuracy: 0.8799 - lr: 9.7687e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.0009764836620835484.\n",
      "Epoch 120/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.3212 - accuracy: 0.8671 - val_loss: 0.2892 - val_accuracy: 0.8816 - lr: 9.7648e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.0009760932495273123.\n",
      "Epoch 121/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3175 - accuracy: 0.8687 - val_loss: 0.3014 - val_accuracy: 0.8773 - lr: 9.7609e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.0009756996976263397.\n",
      "Epoch 122/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3184 - accuracy: 0.8696 - val_loss: 0.2969 - val_accuracy: 0.8759 - lr: 9.7570e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.0009753030645960107.\n",
      "Epoch 123/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3212 - accuracy: 0.8679 - val_loss: 0.2892 - val_accuracy: 0.8819 - lr: 9.7530e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.0009749033504671238.\n",
      "Epoch 124/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3202 - accuracy: 0.8683 - val_loss: 0.3132 - val_accuracy: 0.8685 - lr: 9.7490e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.0009745005552704774.\n",
      "Epoch 125/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3233 - accuracy: 0.8691 - val_loss: 0.3025 - val_accuracy: 0.8785 - lr: 9.7450e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.0009740946790368693.\n",
      "Epoch 126/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3162 - accuracy: 0.8694 - val_loss: 0.2894 - val_accuracy: 0.8848 - lr: 9.7409e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.0009736857217970969.\n",
      "Epoch 127/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3245 - accuracy: 0.8661 - val_loss: 0.2844 - val_accuracy: 0.8820 - lr: 9.7369e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.0009732736835819572.\n",
      "Epoch 128/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3228 - accuracy: 0.8644 - val_loss: 0.2954 - val_accuracy: 0.8816 - lr: 9.7327e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.0009728586226050834.\n",
      "Epoch 129/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3176 - accuracy: 0.8674 - val_loss: 0.2855 - val_accuracy: 0.8852 - lr: 9.7286e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.0009724404807140472.\n",
      "Epoch 130/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3222 - accuracy: 0.8678 - val_loss: 0.2965 - val_accuracy: 0.8807 - lr: 9.7244e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.0009720192579396448.\n",
      "Epoch 131/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3265 - accuracy: 0.8653 - val_loss: 0.2934 - val_accuracy: 0.8812 - lr: 9.7202e-04\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.000971595012494926.\n",
      "Epoch 132/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3205 - accuracy: 0.8683 - val_loss: 0.2861 - val_accuracy: 0.8820 - lr: 9.7160e-04\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.0009711676862280435.\n",
      "Epoch 133/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3201 - accuracy: 0.8693 - val_loss: 0.2999 - val_accuracy: 0.8797 - lr: 9.7117e-04\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.0009707373373516588.\n",
      "Epoch 134/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3234 - accuracy: 0.8678 - val_loss: 0.2933 - val_accuracy: 0.8805 - lr: 9.7074e-04\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.0009703039077143114.\n",
      "Epoch 135/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3166 - accuracy: 0.8700 - val_loss: 0.2858 - val_accuracy: 0.8829 - lr: 9.7030e-04\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.0009698674555282744.\n",
      "Epoch 136/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3181 - accuracy: 0.8694 - val_loss: 0.2922 - val_accuracy: 0.8805 - lr: 9.6987e-04\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.0009694279808237595.\n",
      "Epoch 137/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3123 - accuracy: 0.8700 - val_loss: 0.2830 - val_accuracy: 0.8879 - lr: 9.6943e-04\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.000968985483630978.\n",
      "Epoch 138/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3197 - accuracy: 0.8661 - val_loss: 0.2721 - val_accuracy: 0.8878 - lr: 9.6899e-04\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.0009685399639801413.\n",
      "Epoch 139/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3230 - accuracy: 0.8664 - val_loss: 0.2785 - val_accuracy: 0.8876 - lr: 9.6854e-04\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.0009680914219014595.\n",
      "Epoch 140/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3228 - accuracy: 0.8668 - val_loss: 0.2934 - val_accuracy: 0.8820 - lr: 9.6809e-04\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.0009676398574251429.\n",
      "Epoch 141/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3195 - accuracy: 0.8700 - val_loss: 0.2909 - val_accuracy: 0.8799 - lr: 9.6764e-04\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.0009671852705814013.\n",
      "Epoch 142/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3134 - accuracy: 0.8716 - val_loss: 0.2838 - val_accuracy: 0.8849 - lr: 9.6719e-04\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.0009667276614004442.\n",
      "Epoch 143/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3105 - accuracy: 0.8726 - val_loss: 0.2861 - val_accuracy: 0.8856 - lr: 9.6673e-04\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.000966267088092409.\n",
      "Epoch 144/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3169 - accuracy: 0.8684 - val_loss: 0.2883 - val_accuracy: 0.8851 - lr: 9.6627e-04\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.0009658034925071879.\n",
      "Epoch 145/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3106 - accuracy: 0.8720 - val_loss: 0.2706 - val_accuracy: 0.8880 - lr: 9.6580e-04\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.0009653369328545301.\n",
      "Epoch 146/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3126 - accuracy: 0.8721 - val_loss: 0.2886 - val_accuracy: 0.8799 - lr: 9.6534e-04\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.0009648673509847148.\n",
      "Epoch 147/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3170 - accuracy: 0.8683 - val_loss: 0.2790 - val_accuracy: 0.8899 - lr: 9.6487e-04\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.0009643948051071027.\n",
      "Epoch 148/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3197 - accuracy: 0.8684 - val_loss: 0.2868 - val_accuracy: 0.8839 - lr: 9.6439e-04\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.0009639192952513191.\n",
      "Epoch 149/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3142 - accuracy: 0.8699 - val_loss: 0.2837 - val_accuracy: 0.8813 - lr: 9.6392e-04\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.0009634407632682236.\n",
      "Epoch 150/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3200 - accuracy: 0.8674 - val_loss: 0.2785 - val_accuracy: 0.8895 - lr: 9.6344e-04\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.0009629592673665938.\n",
      "Epoch 151/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3166 - accuracy: 0.8691 - val_loss: 0.2818 - val_accuracy: 0.8854 - lr: 9.6296e-04\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.0009624748075760543.\n",
      "Epoch 152/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3105 - accuracy: 0.8701 - val_loss: 0.2677 - val_accuracy: 0.8944 - lr: 9.6247e-04\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.0009619873839262288.\n",
      "Epoch 153/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3162 - accuracy: 0.8698 - val_loss: 0.2948 - val_accuracy: 0.8787 - lr: 9.6199e-04\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.0009614969964467408.\n",
      "Epoch 154/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3125 - accuracy: 0.8705 - val_loss: 0.2857 - val_accuracy: 0.8813 - lr: 9.6150e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.0009610037033450098.\n",
      "Epoch 155/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3125 - accuracy: 0.8735 - val_loss: 0.2856 - val_accuracy: 0.8805 - lr: 9.6100e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.0009605074464724745.\n",
      "Epoch 156/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3137 - accuracy: 0.8688 - val_loss: 0.2775 - val_accuracy: 0.8878 - lr: 9.6051e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.0009600082258587571.\n",
      "Epoch 157/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3134 - accuracy: 0.8703 - val_loss: 0.2955 - val_accuracy: 0.8764 - lr: 9.6001e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.0009595060997106945.\n",
      "Epoch 158/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3169 - accuracy: 0.8701 - val_loss: 0.2704 - val_accuracy: 0.8942 - lr: 9.5951e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.0009590010098803059.\n",
      "Epoch 159/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3162 - accuracy: 0.8668 - val_loss: 0.2889 - val_accuracy: 0.8808 - lr: 9.5900e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.0009584930145740391.\n",
      "Epoch 160/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3130 - accuracy: 0.8705 - val_loss: 0.2782 - val_accuracy: 0.8868 - lr: 9.5849e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.0009579821138209336.\n",
      "Epoch 161/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3093 - accuracy: 0.8725 - val_loss: 0.2770 - val_accuracy: 0.8833 - lr: 9.5798e-04\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.0009574682494735889.\n",
      "Epoch 162/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3108 - accuracy: 0.8719 - val_loss: 0.2797 - val_accuracy: 0.8841 - lr: 9.5747e-04\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.0009569514797378705.\n",
      "Epoch 163/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.3144 - accuracy: 0.8719 - val_loss: 0.2697 - val_accuracy: 0.8935 - lr: 9.5695e-04\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.0009564318046428166.\n",
      "Epoch 164/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3157 - accuracy: 0.8697 - val_loss: 0.3049 - val_accuracy: 0.8737 - lr: 9.5643e-04\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.0009559092242174648.\n",
      "Epoch 165/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3098 - accuracy: 0.8743 - val_loss: 0.2765 - val_accuracy: 0.8898 - lr: 9.5591e-04\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.0009553837384908525.\n",
      "Epoch 166/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3092 - accuracy: 0.8729 - val_loss: 0.2815 - val_accuracy: 0.8841 - lr: 9.5538e-04\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.0009548554056674873.\n",
      "Epoch 167/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3113 - accuracy: 0.8731 - val_loss: 0.2779 - val_accuracy: 0.8847 - lr: 9.5486e-04\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 0.0009543241676005475.\n",
      "Epoch 168/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3129 - accuracy: 0.8710 - val_loss: 0.2768 - val_accuracy: 0.8888 - lr: 9.5432e-04\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 0.0009537900243190694.\n",
      "Epoch 169/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3145 - accuracy: 0.8705 - val_loss: 0.3014 - val_accuracy: 0.8760 - lr: 9.5379e-04\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 0.0009532530340269776.\n",
      "Epoch 170/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3101 - accuracy: 0.8715 - val_loss: 0.2673 - val_accuracy: 0.8911 - lr: 9.5325e-04\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 0.0009527131385780309.\n",
      "Epoch 171/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3072 - accuracy: 0.8742 - val_loss: 0.2813 - val_accuracy: 0.8851 - lr: 9.5271e-04\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 0.0009521703961757658.\n",
      "Epoch 172/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3111 - accuracy: 0.8716 - val_loss: 0.2821 - val_accuracy: 0.8837 - lr: 9.5217e-04\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 0.0009516248068486355.\n",
      "Epoch 173/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3075 - accuracy: 0.8739 - val_loss: 0.2790 - val_accuracy: 0.8841 - lr: 9.5162e-04\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 0.000951076370625093.\n",
      "Epoch 174/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3125 - accuracy: 0.8693 - val_loss: 0.2830 - val_accuracy: 0.8825 - lr: 9.5108e-04\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 0.0009505250875335906.\n",
      "Epoch 175/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3061 - accuracy: 0.8746 - val_loss: 0.2698 - val_accuracy: 0.8879 - lr: 9.5053e-04\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 0.0009499709576025804.\n",
      "Epoch 176/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3106 - accuracy: 0.8728 - val_loss: 0.2722 - val_accuracy: 0.8923 - lr: 9.4997e-04\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 0.0009494139808605142.\n",
      "Epoch 177/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3103 - accuracy: 0.8716 - val_loss: 0.2959 - val_accuracy: 0.8749 - lr: 9.4941e-04\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 0.0009488541573358433.\n",
      "Epoch 178/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3130 - accuracy: 0.8695 - val_loss: 0.2781 - val_accuracy: 0.8839 - lr: 9.4885e-04\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 0.0009482914870570187.\n",
      "Epoch 179/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3047 - accuracy: 0.8731 - val_loss: 0.2763 - val_accuracy: 0.8862 - lr: 9.4829e-04\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 0.0009477260282254417.\n",
      "Epoch 180/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3075 - accuracy: 0.8709 - val_loss: 0.2644 - val_accuracy: 0.8957 - lr: 9.4773e-04\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 0.0009471577226962242.\n",
      "Epoch 181/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3089 - accuracy: 0.8729 - val_loss: 0.2715 - val_accuracy: 0.8883 - lr: 9.4716e-04\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 0.0009465866286703792.\n",
      "Epoch 182/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3073 - accuracy: 0.8744 - val_loss: 0.2678 - val_accuracy: 0.8923 - lr: 9.4659e-04\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 0.0009460126880034053.\n",
      "Epoch 183/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3057 - accuracy: 0.8738 - val_loss: 0.2733 - val_accuracy: 0.8882 - lr: 9.4601e-04\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.0009454359588959274.\n",
      "Epoch 184/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3134 - accuracy: 0.8699 - val_loss: 0.2710 - val_accuracy: 0.8895 - lr: 9.4544e-04\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.0009448564413758127.\n",
      "Epoch 185/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3051 - accuracy: 0.8729 - val_loss: 0.2773 - val_accuracy: 0.8875 - lr: 9.4486e-04\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.0009442741354709284.\n",
      "Epoch 186/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3080 - accuracy: 0.8742 - val_loss: 0.2827 - val_accuracy: 0.8903 - lr: 9.4427e-04\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.0009436890412091408.\n",
      "Epoch 187/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3042 - accuracy: 0.8749 - val_loss: 0.2677 - val_accuracy: 0.8931 - lr: 9.4369e-04\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.0009431011586183162.\n",
      "Epoch 188/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3117 - accuracy: 0.8731 - val_loss: 0.2673 - val_accuracy: 0.8895 - lr: 9.4310e-04\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.0009425105458975273.\n",
      "Epoch 189/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3122 - accuracy: 0.8694 - val_loss: 0.2729 - val_accuracy: 0.8898 - lr: 9.4251e-04\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.0009419171449030454.\n",
      "Epoch 190/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3103 - accuracy: 0.8732 - val_loss: 0.2740 - val_accuracy: 0.8878 - lr: 9.4192e-04\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.0009413209556627351.\n",
      "Epoch 191/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3047 - accuracy: 0.8749 - val_loss: 0.2731 - val_accuracy: 0.8866 - lr: 9.4132e-04\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.0009407220363750869.\n",
      "Epoch 192/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3029 - accuracy: 0.8744 - val_loss: 0.2746 - val_accuracy: 0.8886 - lr: 9.4072e-04\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.0009401203870673839.\n",
      "Epoch 193/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3004 - accuracy: 0.8757 - val_loss: 0.2574 - val_accuracy: 0.8989 - lr: 9.4012e-04\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.0009395159495966706.\n",
      "Epoch 194/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3023 - accuracy: 0.8761 - val_loss: 0.2573 - val_accuracy: 0.8971 - lr: 9.3952e-04\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.0009389087821608551.\n",
      "Epoch 195/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3114 - accuracy: 0.8712 - val_loss: 0.2658 - val_accuracy: 0.8931 - lr: 9.3891e-04\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.000938298884787219.\n",
      "Epoch 196/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3048 - accuracy: 0.8733 - val_loss: 0.2700 - val_accuracy: 0.8862 - lr: 9.3830e-04\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.000937686257503044.\n",
      "Epoch 197/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3023 - accuracy: 0.8758 - val_loss: 0.2584 - val_accuracy: 0.8974 - lr: 9.3769e-04\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.0009370709003356113.\n",
      "Epoch 198/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3043 - accuracy: 0.8725 - val_loss: 0.2752 - val_accuracy: 0.8880 - lr: 9.3707e-04\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.0009364528133122018.\n",
      "Epoch 199/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3085 - accuracy: 0.8723 - val_loss: 0.2900 - val_accuracy: 0.8771 - lr: 9.3645e-04\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.0009358320546291716.\n",
      "Epoch 200/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3027 - accuracy: 0.8756 - val_loss: 0.2614 - val_accuracy: 0.8951 - lr: 9.3583e-04\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 0.0009352085661443371.\n",
      "Epoch 201/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3077 - accuracy: 0.8721 - val_loss: 0.2657 - val_accuracy: 0.8955 - lr: 9.3521e-04\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 0.0009345824060536666.\n",
      "Epoch 202/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2997 - accuracy: 0.8757 - val_loss: 0.2631 - val_accuracy: 0.8946 - lr: 9.3458e-04\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 0.0009339535162153638.\n",
      "Epoch 203/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3022 - accuracy: 0.8751 - val_loss: 0.2755 - val_accuracy: 0.8868 - lr: 9.3395e-04\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 0.0009333219548250081.\n",
      "Epoch 204/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3037 - accuracy: 0.8754 - val_loss: 0.2567 - val_accuracy: 0.8982 - lr: 9.3332e-04\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 0.0009326877219092969.\n",
      "Epoch 205/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3026 - accuracy: 0.8761 - val_loss: 0.2606 - val_accuracy: 0.8950 - lr: 9.3269e-04\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 0.0009320508174949271.\n",
      "Epoch 206/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3028 - accuracy: 0.8736 - val_loss: 0.2658 - val_accuracy: 0.8924 - lr: 9.3205e-04\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 0.0009314112416085956.\n",
      "Epoch 207/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3045 - accuracy: 0.8736 - val_loss: 0.2589 - val_accuracy: 0.8904 - lr: 9.3141e-04\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 0.0009307689942769985.\n",
      "Epoch 208/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3016 - accuracy: 0.8749 - val_loss: 0.2565 - val_accuracy: 0.8944 - lr: 9.3077e-04\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 0.0009301241336941634.\n",
      "Epoch 209/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3019 - accuracy: 0.8754 - val_loss: 0.2643 - val_accuracy: 0.8920 - lr: 9.3012e-04\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 0.000929476601719067.\n",
      "Epoch 210/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2929 - accuracy: 0.8796 - val_loss: 0.2571 - val_accuracy: 0.8961 - lr: 9.2948e-04\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 0.000928826398378404.\n",
      "Epoch 211/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3017 - accuracy: 0.8747 - val_loss: 0.2667 - val_accuracy: 0.8902 - lr: 9.2883e-04\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 0.0009281735818656199.\n",
      "Epoch 212/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.3046 - accuracy: 0.8753 - val_loss: 0.2675 - val_accuracy: 0.8844 - lr: 9.2817e-04\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 0.0009275181522068281.\n",
      "Epoch 213/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3055 - accuracy: 0.8738 - val_loss: 0.2557 - val_accuracy: 0.8944 - lr: 9.2752e-04\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 0.0009268601094281412.\n",
      "Epoch 214/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2981 - accuracy: 0.8779 - val_loss: 0.2717 - val_accuracy: 0.8883 - lr: 9.2686e-04\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 0.000926199395389503.\n",
      "Epoch 215/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3003 - accuracy: 0.8757 - val_loss: 0.2600 - val_accuracy: 0.8957 - lr: 9.2620e-04\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 0.0009255360682835822.\n",
      "Epoch 216/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3038 - accuracy: 0.8719 - val_loss: 0.2706 - val_accuracy: 0.8875 - lr: 9.2554e-04\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 0.0009248701863022722.\n",
      "Epoch 217/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.3007 - accuracy: 0.8766 - val_loss: 0.2606 - val_accuracy: 0.8934 - lr: 9.2487e-04\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 0.0009242016913055154.\n",
      "Epoch 218/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.3002 - accuracy: 0.8755 - val_loss: 0.2765 - val_accuracy: 0.8825 - lr: 9.2420e-04\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 0.000923530583319423.\n",
      "Epoch 219/300\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.2972 - accuracy: 0.8774 - val_loss: 0.2624 - val_accuracy: 0.8915 - lr: 9.2353e-04\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 0.0009228569205353065.\n",
      "Epoch 220/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.2652 - val_accuracy: 0.8920 - lr: 9.2286e-04\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 0.0009221806448136881.\n",
      "Epoch 221/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3032 - accuracy: 0.8755 - val_loss: 0.2640 - val_accuracy: 0.8868 - lr: 9.2218e-04\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 0.0009215018143454909.\n",
      "Epoch 222/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.2984 - accuracy: 0.8764 - val_loss: 0.2487 - val_accuracy: 0.8983 - lr: 9.2150e-04\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 0.0009208204291562437.\n",
      "Epoch 223/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2992 - accuracy: 0.8774 - val_loss: 0.2633 - val_accuracy: 0.8935 - lr: 9.2082e-04\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 0.0009201364892714744.\n",
      "Epoch 224/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2980 - accuracy: 0.8776 - val_loss: 0.2597 - val_accuracy: 0.8944 - lr: 9.2014e-04\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 0.0009194499947167112.\n",
      "Epoch 225/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.3009 - accuracy: 0.8761 - val_loss: 0.2621 - val_accuracy: 0.8906 - lr: 9.1945e-04\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 0.0009187609455174814.\n",
      "Epoch 226/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3001 - accuracy: 0.8765 - val_loss: 0.2710 - val_accuracy: 0.8872 - lr: 9.1876e-04\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 0.0009180693416993123.\n",
      "Epoch 227/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.3027 - accuracy: 0.8770 - val_loss: 0.2522 - val_accuracy: 0.8961 - lr: 9.1807e-04\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 0.0009173751832877309.\n",
      "Epoch 228/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2954 - accuracy: 0.8776 - val_loss: 0.2582 - val_accuracy: 0.8959 - lr: 9.1738e-04\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 0.0009166785284717204.\n",
      "Epoch 229/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2987 - accuracy: 0.8764 - val_loss: 0.2558 - val_accuracy: 0.8970 - lr: 9.1668e-04\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 0.0009159793191129629.\n",
      "Epoch 230/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.2924 - accuracy: 0.8785 - val_loss: 0.2432 - val_accuracy: 0.9031 - lr: 9.1598e-04\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 0.0009152776134000531.\n",
      "Epoch 231/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2990 - accuracy: 0.8761 - val_loss: 0.2564 - val_accuracy: 0.8967 - lr: 9.1528e-04\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 0.0009145734113579357.\n",
      "Epoch 232/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2975 - accuracy: 0.8749 - val_loss: 0.2576 - val_accuracy: 0.9014 - lr: 9.1457e-04\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 0.0009138667130115546.\n",
      "Epoch 233/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2982 - accuracy: 0.8766 - val_loss: 0.2628 - val_accuracy: 0.8938 - lr: 9.1387e-04\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 0.0009131575183858534.\n",
      "Epoch 234/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2937 - accuracy: 0.8791 - val_loss: 0.2509 - val_accuracy: 0.9025 - lr: 9.1316e-04\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 0.0009124458275057755.\n",
      "Epoch 235/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2959 - accuracy: 0.8780 - val_loss: 0.2623 - val_accuracy: 0.8915 - lr: 9.1245e-04\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 0.000911731640396264.\n",
      "Epoch 236/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2901 - accuracy: 0.8799 - val_loss: 0.2581 - val_accuracy: 0.8987 - lr: 9.1173e-04\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 0.0009110149570822613.\n",
      "Epoch 237/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2994 - accuracy: 0.8775 - val_loss: 0.2410 - val_accuracy: 0.9002 - lr: 9.1101e-04\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 0.0009102958357504233.\n",
      "Epoch 238/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2975 - accuracy: 0.8777 - val_loss: 0.2467 - val_accuracy: 0.9011 - lr: 9.1030e-04\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 0.0009095742182635911.\n",
      "Epoch 239/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2968 - accuracy: 0.8784 - val_loss: 0.2703 - val_accuracy: 0.8868 - lr: 9.0957e-04\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 0.0009088501628080324.\n",
      "Epoch 240/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2948 - accuracy: 0.8792 - val_loss: 0.2550 - val_accuracy: 0.8954 - lr: 9.0885e-04\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 0.000908123669408107.\n",
      "Epoch 241/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2914 - accuracy: 0.8802 - val_loss: 0.2440 - val_accuracy: 0.8999 - lr: 9.0812e-04\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 0.000907394738088175.\n",
      "Epoch 242/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2946 - accuracy: 0.8796 - val_loss: 0.2535 - val_accuracy: 0.8977 - lr: 9.0739e-04\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 0.0009066633688725959.\n",
      "Epoch 243/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2957 - accuracy: 0.8771 - val_loss: 0.2499 - val_accuracy: 0.8994 - lr: 9.0666e-04\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 0.0009059295617857289.\n",
      "Epoch 244/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2981 - accuracy: 0.8772 - val_loss: 0.2470 - val_accuracy: 0.9026 - lr: 9.0593e-04\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 0.000905193316851933.\n",
      "Epoch 245/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2973 - accuracy: 0.8781 - val_loss: 0.2653 - val_accuracy: 0.8895 - lr: 9.0519e-04\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 0.0009044546922557302.\n",
      "Epoch 246/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2938 - accuracy: 0.8787 - val_loss: 0.2525 - val_accuracy: 0.9025 - lr: 9.0445e-04\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 0.0009037136298609278.\n",
      "Epoch 247/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2958 - accuracy: 0.8779 - val_loss: 0.2576 - val_accuracy: 0.8991 - lr: 9.0371e-04\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 0.0009029701878516599.\n",
      "Epoch 248/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2964 - accuracy: 0.8757 - val_loss: 0.2404 - val_accuracy: 0.9030 - lr: 9.0297e-04\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 0.0009022243662517029.\n",
      "Epoch 249/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2947 - accuracy: 0.8772 - val_loss: 0.2513 - val_accuracy: 0.8983 - lr: 9.0222e-04\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 0.0009014761650848329.\n",
      "Epoch 250/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2978 - accuracy: 0.8762 - val_loss: 0.2460 - val_accuracy: 0.9030 - lr: 9.0148e-04\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 0.0009007255843748261.\n",
      "Epoch 251/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2925 - accuracy: 0.8804 - val_loss: 0.2496 - val_accuracy: 0.9002 - lr: 9.0073e-04\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 0.0008999726241454576.\n",
      "Epoch 252/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.2901 - accuracy: 0.8813 - val_loss: 0.2521 - val_accuracy: 0.8978 - lr: 8.9997e-04\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 0.0008992172844205028.\n",
      "Epoch 253/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2979 - accuracy: 0.8775 - val_loss: 0.2499 - val_accuracy: 0.8979 - lr: 8.9922e-04\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 0.0008984595652237365.\n",
      "Epoch 254/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2952 - accuracy: 0.8784 - val_loss: 0.2430 - val_accuracy: 0.9015 - lr: 8.9846e-04\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 0.0008976995247373537.\n",
      "Epoch 255/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2914 - accuracy: 0.8805 - val_loss: 0.2515 - val_accuracy: 0.8957 - lr: 8.9770e-04\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 0.0008969371048263208.\n",
      "Epoch 256/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.2901 - accuracy: 0.8798 - val_loss: 0.2495 - val_accuracy: 0.8998 - lr: 8.9694e-04\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 0.0008961723636724448.\n",
      "Epoch 257/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2950 - accuracy: 0.8796 - val_loss: 0.2423 - val_accuracy: 0.9046 - lr: 8.9617e-04\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 0.000895405301298918.\n",
      "Epoch 258/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2968 - accuracy: 0.8795 - val_loss: 0.2602 - val_accuracy: 0.8887 - lr: 8.9541e-04\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 0.0008946359177289328.\n",
      "Epoch 259/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2906 - accuracy: 0.8809 - val_loss: 0.2568 - val_accuracy: 0.8939 - lr: 8.9464e-04\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 0.0008938642129856811.\n",
      "Epoch 260/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2961 - accuracy: 0.8794 - val_loss: 0.2578 - val_accuracy: 0.8947 - lr: 8.9386e-04\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 0.0008930901870923549.\n",
      "Epoch 261/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2922 - accuracy: 0.8780 - val_loss: 0.2426 - val_accuracy: 0.9025 - lr: 8.9309e-04\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 0.0008923138982292092.\n",
      "Epoch 262/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2910 - accuracy: 0.8791 - val_loss: 0.2457 - val_accuracy: 0.9011 - lr: 8.9231e-04\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 0.0008915352882619835.\n",
      "Epoch 263/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2879 - accuracy: 0.8802 - val_loss: 0.2409 - val_accuracy: 0.9062 - lr: 8.9154e-04\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 0.0008907544153705455.\n",
      "Epoch 264/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2909 - accuracy: 0.8818 - val_loss: 0.2568 - val_accuracy: 0.8958 - lr: 8.9075e-04\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 0.0008899712214210214.\n",
      "Epoch 265/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2937 - accuracy: 0.8784 - val_loss: 0.2423 - val_accuracy: 0.9015 - lr: 8.8997e-04\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 0.0008891857645928909.\n",
      "Epoch 266/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2949 - accuracy: 0.8795 - val_loss: 0.2461 - val_accuracy: 0.8975 - lr: 8.8919e-04\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 0.0008883980449087625.\n",
      "Epoch 267/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2900 - accuracy: 0.8808 - val_loss: 0.2385 - val_accuracy: 0.9053 - lr: 8.8840e-04\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 0.0008876080623912446.\n",
      "Epoch 268/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2885 - accuracy: 0.8820 - val_loss: 0.2507 - val_accuracy: 0.9011 - lr: 8.8761e-04\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 0.0008868158170629457.\n",
      "Epoch 269/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2871 - accuracy: 0.8837 - val_loss: 0.2445 - val_accuracy: 0.8999 - lr: 8.8682e-04\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 0.0008860213671019882.\n",
      "Epoch 270/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2862 - accuracy: 0.8823 - val_loss: 0.2357 - val_accuracy: 0.9078 - lr: 8.8602e-04\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 0.0008852246543750777.\n",
      "Epoch 271/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2907 - accuracy: 0.8818 - val_loss: 0.2608 - val_accuracy: 0.8922 - lr: 8.8522e-04\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 0.0008844257370599484.\n",
      "Epoch 272/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2903 - accuracy: 0.8787 - val_loss: 0.2490 - val_accuracy: 0.9029 - lr: 8.8443e-04\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 0.0008836245570236929.\n",
      "Epoch 273/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2886 - accuracy: 0.8824 - val_loss: 0.2390 - val_accuracy: 0.9033 - lr: 8.8362e-04\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 0.0008828211724436577.\n",
      "Epoch 274/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2893 - accuracy: 0.8799 - val_loss: 0.2397 - val_accuracy: 0.9052 - lr: 8.8282e-04\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 0.0008820155833418681.\n",
      "Epoch 275/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2809 - accuracy: 0.8843 - val_loss: 0.2273 - val_accuracy: 0.9124 - lr: 8.8202e-04\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 0.0008812077897403492.\n",
      "Epoch 276/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2848 - accuracy: 0.8825 - val_loss: 0.2420 - val_accuracy: 0.9021 - lr: 8.8121e-04\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 0.000880397849815285.\n",
      "Epoch 277/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2915 - accuracy: 0.8782 - val_loss: 0.2462 - val_accuracy: 0.9013 - lr: 8.8040e-04\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 0.0008795857054341533.\n",
      "Epoch 278/300\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 0.2932 - accuracy: 0.8785 - val_loss: 0.2401 - val_accuracy: 0.9017 - lr: 8.7959e-04\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 0.0008787713566189783.\n",
      "Epoch 279/300\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 0.2870 - accuracy: 0.8822 - val_loss: 0.2357 - val_accuracy: 0.9056 - lr: 8.7877e-04\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 0.0008779548615453619.\n",
      "Epoch 280/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2857 - accuracy: 0.8818 - val_loss: 0.2398 - val_accuracy: 0.9038 - lr: 8.7795e-04\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 0.0008771362202347469.\n",
      "Epoch 281/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2893 - accuracy: 0.8823 - val_loss: 0.2351 - val_accuracy: 0.9078 - lr: 8.7714e-04\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 0.0008763154327085753.\n",
      "Epoch 282/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2852 - accuracy: 0.8835 - val_loss: 0.2422 - val_accuracy: 0.9039 - lr: 8.7632e-04\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 0.0008754924408352921.\n",
      "Epoch 283/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2885 - accuracy: 0.8810 - val_loss: 0.2354 - val_accuracy: 0.9096 - lr: 8.7549e-04\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 0.0008746673609425268.\n",
      "Epoch 284/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2864 - accuracy: 0.8822 - val_loss: 0.2414 - val_accuracy: 0.9034 - lr: 8.7467e-04\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 0.0008738401348985302.\n",
      "Epoch 285/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2867 - accuracy: 0.8822 - val_loss: 0.2410 - val_accuracy: 0.9027 - lr: 8.7384e-04\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 0.0008730107627247435.\n",
      "Epoch 286/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2845 - accuracy: 0.8824 - val_loss: 0.2302 - val_accuracy: 0.9096 - lr: 8.7301e-04\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 0.0008721793025948298.\n",
      "Epoch 287/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2885 - accuracy: 0.8811 - val_loss: 0.2218 - val_accuracy: 0.9145 - lr: 8.7218e-04\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 0.0008713456963776201.\n",
      "Epoch 288/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2827 - accuracy: 0.8810 - val_loss: 0.2394 - val_accuracy: 0.9031 - lr: 8.7135e-04\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 0.0008705100022463897.\n",
      "Epoch 289/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2847 - accuracy: 0.8828 - val_loss: 0.2338 - val_accuracy: 0.9066 - lr: 8.7051e-04\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 0.0008696722202219977.\n",
      "Epoch 290/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2853 - accuracy: 0.8811 - val_loss: 0.2408 - val_accuracy: 0.9003 - lr: 8.6967e-04\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 0.000868832350325303.\n",
      "Epoch 291/300\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 0.2869 - accuracy: 0.8815 - val_loss: 0.2485 - val_accuracy: 0.9003 - lr: 8.6883e-04\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 0.0008679903925771639.\n",
      "Epoch 292/300\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.2871 - accuracy: 0.8812 - val_loss: 0.2369 - val_accuracy: 0.9026 - lr: 8.6799e-04\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 0.0008671463469984386.\n",
      "Epoch 293/300\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 0.2900 - accuracy: 0.8812 - val_loss: 0.2319 - val_accuracy: 0.9088 - lr: 8.6715e-04\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 0.000866300271760852.\n",
      "Epoch 294/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2854 - accuracy: 0.8833 - val_loss: 0.2493 - val_accuracy: 0.8973 - lr: 8.6630e-04\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 0.0008654521087340076.\n",
      "Epoch 295/300\n",
      "59/59 [==============================] - 3s 50ms/step - loss: 0.2855 - accuracy: 0.8819 - val_loss: 0.2357 - val_accuracy: 0.9018 - lr: 8.6545e-04\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 0.0008646019160892423.\n",
      "Epoch 296/300\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.2955 - accuracy: 0.8795 - val_loss: 0.2459 - val_accuracy: 0.8994 - lr: 8.6460e-04\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 0.0008637496938468324.\n",
      "Epoch 297/300\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.2893 - accuracy: 0.8812 - val_loss: 0.2363 - val_accuracy: 0.9076 - lr: 8.6375e-04\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 0.0008628954420270538.\n",
      "Epoch 298/300\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.2860 - accuracy: 0.8804 - val_loss: 0.2381 - val_accuracy: 0.9047 - lr: 8.6290e-04\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 0.000862039160650182.\n",
      "Epoch 299/300\n",
      "59/59 [==============================] - 3s 50ms/step - loss: 0.2830 - accuracy: 0.8852 - val_loss: 0.2506 - val_accuracy: 0.8981 - lr: 8.6204e-04\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 0.0008611808497364925.\n",
      "Epoch 300/300\n",
      "59/59 [==============================] - 2s 25ms/step - loss: 0.2824 - accuracy: 0.8839 - val_loss: 0.2416 - val_accuracy: 0.9015 - lr: 8.6118e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x800 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V15. Batch Size 512, initial learning rate 1e-3.\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "epochs = 300\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    return lr * 1 / (1 + decay * epoch)\n",
    "\n",
    "learning_rate = callbacks.LearningRateScheduler(lr_time_based_decay, verbose=1)\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\"classifier_15_512.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(training_set, validation_data=test_set, epochs=300, callbacks = [learning_rate, checkpoint_cb])\n",
    "\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 12)               48        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1300      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               30300     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               150500    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               150300    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 362,952\n",
      "Trainable params: 362,928\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 00:13:09.693422: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-02 00:13:09.696277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/59 [============>.................] - ETA: 0s - loss: 1.0274 - accuracy: 0.5975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(training_set, validation_data\u001B[38;5;241m=\u001B[39mtest_set, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/keras/engine/training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1562\u001B[0m ):\n\u001B[1;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2494\u001B[0m   (graph_function,\n\u001B[1;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1865\u001B[0m     args,\n\u001B[1;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1867\u001B[0m     executing_eagerly)\n\u001B[1;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set, validation_data=test_set, epochs=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
